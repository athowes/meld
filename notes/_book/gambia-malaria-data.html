<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Gambia Malaria Data | Markov Melding Notes</title>
  <meta name="description" content="5 Gambia Malaria Data | Markov Melding Notes" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Gambia Malaria Data | Markov Melding Notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Gambia Malaria Data | Markov Melding Notes" />
  
  
  

<meta name="author" content="Adam Howes" />


<meta name="date" content="2019-07-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="divide-and-conquer-with-smc.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Notation</a></li>
<li class="chapter" data-level="2" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>2</b> Background</a><ul>
<li class="chapter" data-level="2.1" data-path="background.html"><a href="background.html#monte-carlo"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo</a><ul>
<li class="chapter" data-level="2.1.1" data-path="background.html"><a href="background.html#metropolis-hastings-sampler"><i class="fa fa-check"></i><b>2.1.1</b> Metropolis-Hastings sampler</a></li>
<li class="chapter" data-level="2.1.2" data-path="background.html"><a href="background.html#random-scan-gibbs-sampler"><i class="fa fa-check"></i><b>2.1.2</b> (Random scan) Gibbs sampler</a></li>
<li class="chapter" data-level="2.1.3" data-path="background.html"><a href="background.html#random-scan-metropolis-within-gibbs"><i class="fa fa-check"></i><b>2.1.3</b> (Random scan) Metropolis-within-Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="background.html"><a href="background.html#meta-analysis-evidence-synthesis-combining-expert-opinion-etc."><i class="fa fa-check"></i><b>2.2</b> Meta-analysis, evidence synthesis, combining expert opinion etc.</a><ul>
<li class="chapter" data-level="2.2.1" data-path="background.html"><a href="background.html#multiple-experts"><i class="fa fa-check"></i><b>2.2.1</b> Multiple Experts</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="background.html"><a href="background.html#graphical-models"><i class="fa fa-check"></i><b>2.3</b> Graphical models</a><ul>
<li class="chapter" data-level="2.3.1" data-path="background.html"><a href="background.html#bayesian-networks"><i class="fa fa-check"></i><b>2.3.1</b> Bayesian networks</a></li>
<li class="chapter" data-level="2.3.2" data-path="background.html"><a href="background.html#factor-graphs"><i class="fa fa-check"></i><b>2.3.2</b> Factor graphs</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="background.html"><a href="background.html#miscellaneous-reading"><i class="fa fa-check"></i><b>2.4</b> Miscellaneous reading</a><ul>
<li class="chapter" data-level="2.4.1" data-path="background.html"><a href="background.html#bayesian-approaches-to-random-effects-meta-analysis"><i class="fa fa-check"></i><b>2.4.1</b> Bayesian approaches to random-effects meta-analysis</a></li>
<li class="chapter" data-level="2.4.2" data-path="background.html"><a href="background.html#the-statistical-basis-of-meta-analysis"><i class="fa fa-check"></i><b>2.4.2</b> The statistical basis of meta-analysis</a></li>
<li class="chapter" data-level="2.4.3" data-path="background.html"><a href="background.html#bayesian-calibration-of-computer-models"><i class="fa fa-check"></i><b>2.4.3</b> Bayesian calibration of computer models</a></li>
<li class="chapter" data-level="2.4.4" data-path="background.html"><a href="background.html#inference-for-deterministic-simulation-models-the-bayesian-melding-approach"><i class="fa fa-check"></i><b>2.4.4</b> Inference for deterministic simulation models: the Bayesian melding approach</a></li>
<li class="chapter" data-level="2.4.5" data-path="background.html"><a href="background.html#combining-models"><i class="fa fa-check"></i><b>2.4.5</b> Combining Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="markov-melding.html"><a href="markov-melding.html"><i class="fa fa-check"></i><b>3</b> Markov Melding</a><ul>
<li class="chapter" data-level="3.1" data-path="markov-melding.html"><a href="markov-melding.html#introduction-to-markov-melding"><i class="fa fa-check"></i><b>3.1</b> Introduction to Markov melding</a></li>
<li class="chapter" data-level="3.2" data-path="markov-melding.html"><a href="markov-melding.html#markov-combination"><i class="fa fa-check"></i><b>3.2</b> Markov combination</a></li>
<li class="chapter" data-level="3.3" data-path="markov-melding.html"><a href="markov-melding.html#pooling-marginal-distributions"><i class="fa fa-check"></i><b>3.3</b> Pooling marginal distributions</a></li>
<li class="chapter" data-level="3.4" data-path="markov-melding.html"><a href="markov-melding.html#inference-and-computation"><i class="fa fa-check"></i><b>3.4</b> Inference and computation</a><ul>
<li class="chapter" data-level="3.4.1" data-path="markov-melding.html"><a href="markov-melding.html#metropolis-within-gibbs"><i class="fa fa-check"></i><b>3.4.1</b> Metropolis-within-Gibbs</a></li>
<li class="chapter" data-level="3.4.2" data-path="markov-melding.html"><a href="markov-melding.html#multi-stage-metropolis-within-gibbs"><i class="fa fa-check"></i><b>3.4.2</b> Multi-stage Metropolis-within-Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="divide-and-conquer-with-smc.html"><a href="divide-and-conquer-with-smc.html"><i class="fa fa-check"></i><b>4</b> Divide and Conquer with SMC</a></li>
<li class="chapter" data-level="5" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html"><i class="fa fa-check"></i><b>5</b> Gambia Malaria Data</a><ul>
<li class="chapter" data-level="5.1" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Logistic regression</a></li>
<li class="chapter" data-level="5.2" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#full-and-submodels"><i class="fa fa-check"></i><b>5.2</b> Full and submodels</a></li>
<li class="chapter" data-level="5.3" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#monte-carlo-schemes"><i class="fa fa-check"></i><b>5.3</b> Monte Carlo schemes</a><ul>
<li class="chapter" data-level="5.3.1" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#metropolis-within-gibbs-1"><i class="fa fa-check"></i><b>5.3.1</b> Metropolis-within-Gibbs</a></li>
<li class="chapter" data-level="5.3.2" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#multi-stage-metropolis-within-gibbs-1"><i class="fa fa-check"></i><b>5.3.2</b> Multi-stage Metropolis-within-Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>6</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Markov Melding Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gambia-malaria-data" class="section level1">
<h1><span class="header-section-number">5</span> Gambia Malaria Data</h1>
<p>The <code>gambia</code> dataset from the R package geoR contains observations of <span class="math inline">\(n = 2035\)</span> Gambian children. The eight variables measured are:</p>
<ul>
<li><code>x</code> the x-coordinate of the village (Universal Transverse Mercator - similar to latitude and longitude)</li>
<li><code>y</code> the y-coordinate of the village (UTM)</li>
<li><code>pos</code> presence (1) or absence (0) of malaria in a blood sample taken from the child</li>
<li><code>age</code> age of the child, in days</li>
<li><code>netuse</code> indicator variable denoting whether (1) or not (0) the child regularly sleeps under a bed-net</li>
<li><code>treated</code> indicator variable denoting whether (1) or not (0) the bed-net is treated (coded 0 if <code>netuse</code> = 0)</li>
<li><code>green</code> satellite-derived measure of the green-ness of vegetation in the immediate vicinity of the village (arbitrary units)</li>
<li><code>phc</code> indicator variable denoting the presence (1) or absence (0) of a health center in the village</li>
</ul>
<div id="logistic-regression" class="section level2">
<h2><span class="header-section-number">5.1</span> Logistic regression</h2>
<p>Consider response <span class="math inline">\(Y \in \{0, 1\}\)</span> modelled as <span class="math inline">\(Y \sim \text{Bern}(q)\)</span> and covariates <span class="math inline">\(x \in \mathbb{R}^p\)</span> with</p>
<p><span class="math display">\[
\log\left(\frac{q(x)}{1-q(x)}\right) = \beta_0 + \beta^{T} x,
\]</span> where <span class="math inline">\(\beta \in \mathbb{R}^p\)</span>. Then</p>
<p><span class="math display">\[
q(x) = \frac{\exp \left(\beta_0 + \beta^{T} x\right)}{1+ \exp\left(\beta_0 + \beta^{T} x\right)}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Classify to 1 with probability</span>
q &lt;-<span class="st"> </span><span class="cf">function</span>(x, b) {
  <span class="kw">exp</span>(b <span class="op">%*%</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(b <span class="op">%*%</span><span class="st"> </span>x)) 
}</code></pre></div>
<p>Observe labelled data <span class="math inline">\(\mathcal{D} = \{(x_1, y_1), \ldots, (x_n, y_n)\}\)</span>. The likelihood function is</p>
<p><span class="math display">\[
\mathcal{L}(\beta_{0}, \beta) = \prod_{i=1}^{n} q\left(x_i\right)^{y_i}\left(1-q(x_i)\right)^{1-y_i}
\]</span> Place Gaussian priors on <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\beta_0\)</span> such that</p>
<p><span class="math display">\[
\beta_0 \sim \mathcal{N}(\mu_0, \sigma_0^2), \;
\beta \sim \mathcal{N}_p(\mu, \text{diag}(\sigma_1^2, \ldots, \sigma_p^2))
\]</span> Then the posterior is proportional to</p>
<p><span class="math display">\[
p(\beta_0, \beta | y_1, \ldots, y_n) \propto \prod_{j=0}^p\exp\left(\frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2\right) \prod_{i=1}^{n} q\left(x_i\right)^{y_i}\left(1-q\left(x_i\right)\right)^{1-y_i}.
\]</span> Taking the logarithm gives</p>
<p><span class="math display">\[
\log p(\beta_0, \beta | y_1, \ldots, y_n) \propto \sum_{j=0}^p \frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2 +  \sum_{i=1}^{n} \{ {y_i}\log q\left(x_i\right) + (1 - y_i) \log \left(1-q\left(x_i\right)\right)\}.
\]</span> The log-likelihood can be rewritten as</p>
<span class="math display">\[\begin{align*}
\sum_{i=1}^{n} \{ {y_i}\log q\left(x_i\right) + (1 - y_i) \log \left(1-q\left(x_i\right)\right) \}
&amp;= \sum_{i=1}^{n} \{ {y_i}\log \left(\frac{q\left(x_i\right)}{1-q\left(x_i\right)}\right) + \log \left(1-q\left(x_i\right)\right) \} \\
&amp;= \sum_{i=1}^{n} \{ {y_i}\log \left(\frac{q\left(x_i\right)}{1-q\left(x_i\right)}\right) + \log \left(1-q\left(x_i\right)\right) \} \\
&amp;= \sum_{i=1}^{n} \{ {y_i}\left(\beta_0 + \beta^{T} x\right) - \log \left(1 + \exp(\beta_0 + \beta^{T} x)\right)\},
\end{align*}\]</span>
<p>so that the log-posterior is</p>
<p><span class="math display">\[
\log p(\beta_0, \beta | y_1, \ldots, y_n) \propto \sum_{j=0}^p \frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2 + \sum_{i=1}^{n} \{{y_i}\left(\beta_0 + \beta^{T} x\right) - \log \left(1 + \exp(\beta_0 + \beta^{T} x)\right)\}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># (proportional to) log posterior in the indep normals prior case</span>
logpost &lt;-<span class="st"> </span><span class="cf">function</span>(b, X, mu, sigma) {
  logprior &lt;-<span class="st"> </span><span class="kw">sum</span>((b <span class="op">-</span><span class="st"> </span>mu)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>sigma)
  nu &lt;-<span class="st"> </span><span class="kw">apply</span>(X, <span class="dv">1</span>, <span class="cf">function</span>(x) b <span class="op">%*%</span><span class="st"> </span>x) <span class="co"># Vector of linear predictors</span>
  loglike &lt;-<span class="st"> </span><span class="kw">sum</span>(nu[Y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>]) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span><span class="kw">log</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(nu)))
  logprior <span class="op">+</span><span class="st"> </span>loglike
}</code></pre></div>
</div>
<div id="full-and-submodels" class="section level2">
<h2><span class="header-section-number">5.2</span> Full and submodels</h2>
<p>Firstly, the full model <span class="math inline">\(\mathcal{M}\)</span> is the logistic regression of response <code>pos</code> on the other variables including an intercept term but excluding the co-ordinates <code>x</code> and <code>y</code>. <span class="math display">\[
\log\left(\frac{q(x)}{1-q(x)}\right) = \eta
\]</span></p>
<p><span class="math display">\[
\eta = \beta_0 + \beta_1 \cdot \texttt{age} + \beta_2 \cdot \texttt{netuse} + \beta_3 \cdot \texttt{treated} + \beta_4 \cdot \texttt{green} + \beta_5 \cdot \texttt{phc}
\]</span></p>
<p>Define submodels <span class="math inline">\(\mathcal{M}_1\)</span> and <span class="math inline">\(\mathcal{M}_2\)</span> with linear predictors <span class="math display">\[
\eta_1 = \beta_{0,1} + \beta_1 \cdot \texttt{age} +  \beta_4 \cdot \texttt{green} + \beta_5 \cdot \texttt{phc},
\]</span></p>
<p>and <span class="math display">\[
\eta_2 = \beta_{0,2} + \beta_2 \cdot \texttt{netuse} + \beta_3 \cdot \texttt{treated} + \beta_5 \cdot \texttt{phc}.
\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(\text{Intercept}\)</span></th>
<th><span class="math inline">\(\beta_1\)</span></th>
<th><span class="math inline">\(\beta_2\)</span></th>
<th><span class="math inline">\(\beta_3\)</span></th>
<th><span class="math inline">\(\beta_4\)</span></th>
<th><span class="math inline">\(\beta_5\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Submodel 1</td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
<tr class="even">
<td>Submodel 2</td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td><span class="math inline">\(\checkmark\)</span></td>
<td></td>
<td><span class="math inline">\(\checkmark\)</span></td>
</tr>
</tbody>
</table>
<p>The link parameter is <span class="math inline">\(\phi = \beta_5\)</span> and model specific parameters are <span class="math inline">\(\psi_1 = (\beta_{0,1}, \beta_1, \beta_4)\)</span> and <span class="math inline">\(\psi_2 = (\beta_{0,2}, \beta_2, \beta_3)\)</span>. Both submodels have the same observable random variables <span class="math inline">\(Y_1 = Y_2 = Y\)</span>, the response variable <code>pos</code>.</p>
<p>Define <span class="math inline">\(q_k\)</span> for <span class="math inline">\(k = 1, 2\)</span> by <span class="math display">\[
q_k(x) = \frac{\exp \left(\eta_k\right)}{1+ \exp\left(\eta_k\right)}
\]</span></p>
<p>Take a normal prior as in Section 1 for <span class="math inline">\(\beta_{1:5}\)</span>, and similarly take a normal prior for the intercepts <span class="math display">\[
\beta_{0, k} \sim \mathcal{N}(\mu_{0, k}, \sigma_{0, k}^2).
\]</span></p>
<p>Then the submodels have consistent prior marginals in the link parameter and Markov combination can be applied.</p>
<p>The joint distribution corresponding to submodel <span class="math inline">\(\mathcal{M}_1\)</span>, as a function of the parameters, is proportional to the posterior, which itself is proportional to the prior times the likelihood</p>
<span class="math display">\[\begin{align*}
p_1(\phi, \psi_1, \mathbf{y}_1) &amp;\propto p_1(\phi, \psi_1 | \mathbf{y}_1) \\
&amp;= p_1(\beta_{0, 1}, \beta_1, \beta_4, \beta_5 | \mathbf{y}) \\
&amp;\propto \underbrace{\exp\left(\frac{1}{2\sigma_{0,1}^2}(\beta_{0,1} - \mu_{0,1})^2\right) \prod_{j=1,4,5}\exp\left(\frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2\right)}_{\text{Prior on } (\phi, \psi_1) = (\beta_{0,1}, \beta_1, \beta_4, \beta_5)} \times
\underbrace{\prod_{i=1}^{2035} q_1\left(x_i\right)^{y_i}\left(1-q_1\left(x_i\right)\right)^{1-y_i}}_{\text{Likelihood}}.
\end{align*}\]</span>
<p>Similarly for <span class="math inline">\(\mathcal{M}_2\)</span></p>
<span class="math display">\[\begin{align*}
p_2(\phi, \psi_2, \mathbf{y}_2) &amp;\propto p_2(\phi, \psi_2 | \mathbf{y}_2) \\
&amp;= p_2(\beta_{0, 2}, \beta_2, \beta_3, \beta_5 | \mathbf{y}) \\
&amp;\propto \underbrace{\exp\left(\frac{1}{2\sigma_{0,2}^2}(\beta_{0,2} - \mu_{0,2})^2\right) \prod_{j=2,3,5}\exp\left(\frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2\right)}_{\text{Prior on } (\phi, \psi_1) = (\beta_{0,2}, \beta_2, \beta_3, \beta_5)} \times 
\underbrace{\prod_{i=1}^{2035} q_2\left(x_i\right)^{y_i}\left(1-q_2\left(x_i\right)\right)^{1-y_i}}_{\text{Likelihood}}.
\end{align*}\]</span>
<p>Therefore the Markov combination in this case is</p>
<span class="math display">\[\begin{align*}
p_{\mathrm{comb}}\left(\phi, \psi_1, \psi_2, \mathbf{y}_1, \mathbf{y}_2\right) &amp;= \frac{p_1\left(\phi, \psi_1, \mathbf{y}_1\right)p_2\left(\phi, \psi_2, \mathbf{y}_2\right)}{p(\phi)} \\
&amp;\propto \frac{p_1(\beta_{0, 1}, \beta_1, \beta_4, \beta_5 | \mathbf{y}) p_2(\beta_{0, 2}, \beta_2, \beta_3, \beta_5 | \mathbf{y})}{p(\beta_5)} \\
&amp;\propto \prod_{k=1}^2 \exp\left(\frac{1}{2\sigma_{0,k}^2}(\beta_{0,k} - \mu_{0,k})^2\right) \prod_{j=1}^5\exp\left(\frac{1}{2\sigma_j^2}(\beta_j - \mu_j)^2\right) \\
&amp;\times \prod_{i=1}^{2035} q_1\left(x_i\right)^{y_i}\left(1-q_1\left(x_i\right)\right)^{1-y_i} q_2\left(x_i\right)^{y_i}\left(1-q_2\left(x_i\right)\right)^{1-y_i} \tag{*}
\end{align*}\]</span>
<p>Informally <span class="math inline">\(p_{\mathrm{comb}}\)</span> contains the product of the priors on the full set of parameters <span class="math inline">\((\phi, \psi_1, \psi_2)\)</span> with both likelihoods from <span class="math inline">\(\mathcal{M}_1\)</span> and <span class="math inline">\(\mathcal{M}_2\)</span>. So this is almost like Bayesian inference for full model but with a different likelihood. It seems as if the information contained by the data <span class="math inline">\(\mathcal{D}\)</span> is being used more than once.</p>
</div>
<div id="monte-carlo-schemes" class="section level2">
<h2><span class="header-section-number">5.3</span> Monte Carlo schemes</h2>
<p>Want to sample from the target (*) using the methods described in <span class="citation">(Goudie et al. <a href="#ref-goudie2019joining">2019</a>)</span>. Continue to use (symmetric) normal proposals throughout.</p>
<div id="metropolis-within-gibbs-1" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Metropolis-within-Gibbs</h3>
<ul>
<li>Update first latent parameter <span class="math inline">\(\psi_1\)</span> by systematic scan Metropolis-within-Gibbs</li>
<li>Update second latent parameter <span class="math inline">\(\psi_2\)</span> by systematic scan Metropolis-within-Gibbs</li>
<li>Update link parameter <span class="math inline">\(\phi\)</span> by Metropolis-within-Gibbs</li>
</ul>
</div>
<div id="multi-stage-metropolis-within-gibbs-1" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Multi-stage Metropolis-within-Gibbs</h3>

</div>
</div>
</div>
<h3> References</h3>
<div id="refs" class="references">
<div id="ref-goudie2019joining">
<p>Goudie, Robert JB, Anne M Presanis, David Lunn, Daniela De Angelis, and Lorenz Wernisch. 2019. “Joining and Splitting Models with Markov Melding.” <em>Bayesian Analysis</em> 14 (1). Europe PMC Funders: 81.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="divide-and-conquer-with-smc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["melding_notes.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter2 Background | Markov Melding Notes</title>
  <meta name="description" content="Chapter2 Background | Markov Melding Notes" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter2 Background | Markov Melding Notes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter2 Background | Markov Melding Notes" />
  
  
  

<meta name="author" content="Adam Howes" />


<meta name="date" content="2019-07-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html">
<link rel="next" href="markov-melding.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Notation</a></li>
<li class="chapter" data-level="2" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>2</b> Background</a><ul>
<li class="chapter" data-level="2.1" data-path="background.html"><a href="background.html#monte-carlo"><i class="fa fa-check"></i><b>2.1</b> Monte Carlo</a><ul>
<li class="chapter" data-level="2.1.1" data-path="background.html"><a href="background.html#metropolis-hastings-sampler"><i class="fa fa-check"></i><b>2.1.1</b> Metropolis-Hastings sampler</a></li>
<li class="chapter" data-level="2.1.2" data-path="background.html"><a href="background.html#random-scan-gibbs-sampler"><i class="fa fa-check"></i><b>2.1.2</b> (Random scan) Gibbs sampler</a></li>
<li class="chapter" data-level="2.1.3" data-path="background.html"><a href="background.html#random-scan-metropolis-within-gibbs"><i class="fa fa-check"></i><b>2.1.3</b> (Random scan) Metropolis-within-Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="background.html"><a href="background.html#meta-analysis-evidence-synthesis-combining-expert-opinion-etc."><i class="fa fa-check"></i><b>2.2</b> Meta-analysis, evidence synthesis, combining expert opinion etc.</a><ul>
<li class="chapter" data-level="2.2.1" data-path="background.html"><a href="background.html#multiple-experts"><i class="fa fa-check"></i><b>2.2.1</b> Multiple Experts</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="background.html"><a href="background.html#graphical-models"><i class="fa fa-check"></i><b>2.3</b> Graphical models</a><ul>
<li class="chapter" data-level="2.3.1" data-path="background.html"><a href="background.html#bayesian-networks"><i class="fa fa-check"></i><b>2.3.1</b> Bayesian networks</a></li>
<li class="chapter" data-level="2.3.2" data-path="background.html"><a href="background.html#factor-graphs"><i class="fa fa-check"></i><b>2.3.2</b> Factor graphs</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="background.html"><a href="background.html#miscellaneous-reading"><i class="fa fa-check"></i><b>2.4</b> Miscellaneous reading</a><ul>
<li class="chapter" data-level="2.4.1" data-path="background.html"><a href="background.html#bayesian-approaches-to-random-effects-meta-analysis"><i class="fa fa-check"></i><b>2.4.1</b> Bayesian approaches to random-effects meta-analysis</a></li>
<li class="chapter" data-level="2.4.2" data-path="background.html"><a href="background.html#the-statistical-basis-of-meta-analysis"><i class="fa fa-check"></i><b>2.4.2</b> The statistical basis of meta-analysis</a></li>
<li class="chapter" data-level="2.4.3" data-path="background.html"><a href="background.html#bayesian-calibration-of-computer-models"><i class="fa fa-check"></i><b>2.4.3</b> Bayesian calibration of computer models</a></li>
<li class="chapter" data-level="2.4.4" data-path="background.html"><a href="background.html#inference-for-deterministic-simulation-models-the-bayesian-melding-approach"><i class="fa fa-check"></i><b>2.4.4</b> Inference for deterministic simulation models: the Bayesian melding approach</a></li>
<li class="chapter" data-level="2.4.5" data-path="background.html"><a href="background.html#combining-models"><i class="fa fa-check"></i><b>2.4.5</b> Combining Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="markov-melding.html"><a href="markov-melding.html"><i class="fa fa-check"></i><b>3</b> Markov Melding</a><ul>
<li class="chapter" data-level="3.1" data-path="markov-melding.html"><a href="markov-melding.html#introduction-to-markov-melding"><i class="fa fa-check"></i><b>3.1</b> Introduction to Markov melding</a></li>
<li class="chapter" data-level="3.2" data-path="markov-melding.html"><a href="markov-melding.html#markov-combination"><i class="fa fa-check"></i><b>3.2</b> Markov combination</a></li>
<li class="chapter" data-level="3.3" data-path="markov-melding.html"><a href="markov-melding.html#pooling-marginal-distributions"><i class="fa fa-check"></i><b>3.3</b> Pooling marginal distributions</a></li>
<li class="chapter" data-level="3.4" data-path="markov-melding.html"><a href="markov-melding.html#inference-and-computation"><i class="fa fa-check"></i><b>3.4</b> Inference and computation</a><ul>
<li class="chapter" data-level="3.4.1" data-path="markov-melding.html"><a href="markov-melding.html#metropolis-within-gibbs"><i class="fa fa-check"></i><b>3.4.1</b> Metropolis-within-Gibbs</a></li>
<li class="chapter" data-level="3.4.2" data-path="markov-melding.html"><a href="markov-melding.html#multi-stage-metropolis-within-gibbs"><i class="fa fa-check"></i><b>3.4.2</b> Multi-stage Metropolis-within-Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="divide-and-conquer-with-sequential-monte-carlo.html"><a href="divide-and-conquer-with-sequential-monte-carlo.html"><i class="fa fa-check"></i><b>4</b> Divide and Conquer with Sequential Monte Carlo</a></li>
<li class="chapter" data-level="5" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html"><i class="fa fa-check"></i><b>5</b> Gambia Malaria Data</a><ul>
<li class="chapter" data-level="5.1" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#logistic-regression"><i class="fa fa-check"></i><b>5.1</b> Logistic regression</a></li>
<li class="chapter" data-level="5.2" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#full-and-submodels"><i class="fa fa-check"></i><b>5.2</b> Full and submodels</a></li>
<li class="chapter" data-level="5.3" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#monte-carlo-schemes"><i class="fa fa-check"></i><b>5.3</b> Monte Carlo schemes</a><ul>
<li class="chapter" data-level="5.3.1" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#metropolis-within-gibbs-1"><i class="fa fa-check"></i><b>5.3.1</b> Metropolis-within-Gibbs</a></li>
<li class="chapter" data-level="5.3.2" data-path="gambia-malaria-data.html"><a href="gambia-malaria-data.html#multi-stage-metropolis-within-gibbs-1"><i class="fa fa-check"></i><b>5.3.2</b> Multi-stage Metropolis-within-Gibbs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Markov Melding Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="background" class="section level1">
<h1><span class="header-section-number">Chapter2</span> Background</h1>
<div id="monte-carlo" class="section level2">
<h2><span class="header-section-number">2.1</span> Monte Carlo</h2>
<p>Notes from Adam Johansen’s Warwick course.</p>
<p>For the following samplers targeting density <span class="math inline">\(f\)</span> and starting with <span class="math inline">\(x^{(0)} :=\left(x_{1}^{(0)}, \ldots, x_{p}^{(0)}\right)\)</span>, iterate for <span class="math inline">\(t = 1, 2, \ldots\)</span></p>
<div id="metropolis-hastings-sampler" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Metropolis-Hastings sampler</h3>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(x \sim q\left(\cdot | x^{(t-1)}\right)\)</span></li>
<li>With probability <span class="math inline">\(\min \left\{1, \frac{f(x) \cdot q\left(x^{(t-1)} | x\right)}{f\left(x^{(t-1)}\right) \cdot q\left(x | x^{(t-1)}\right)}\right\}\)</span> set <span class="math inline">\(x^{(t)}=x\)</span>, else set <span class="math inline">\(x^{(t)}=x^{(t-1)}\)</span></li>
</ol>
<p>Note that if the proposal <span class="math inline">\(q\)</span> is symmetric (as in random-walk metropolis-hastings) then the acceptance probability simplifies to <span class="math inline">\(\min \left\{1, \frac{f(x)}{f\left(x^{(t-1)}\right)}\right\}\)</span>.</p>
</div>
<div id="random-scan-gibbs-sampler" class="section level3">
<h3><span class="header-section-number">2.1.2</span> (Random scan) Gibbs sampler</h3>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(j \sim \text{Unif}\{1, \ldots, p\}\)</span></li>
<li>Draw <span class="math inline">\(x_{j}^{(t)} \sim f_{x_{j} | x_{-j}}\left(\cdot | x_{1}^{(t-1)}, \ldots, x_{j-1}^{(t-1)}, x_{j+1}^{(t-1)}, \ldots, x_{p}^{(t-1)}\right)\)</span>, and set <span class="math inline">\(x_i^{(t)} :=x_i^{(t-1)}\)</span> for all <span class="math inline">\(i \neq j\)</span></li>
</ol>
</div>
<div id="random-scan-metropolis-within-gibbs" class="section level3">
<h3><span class="header-section-number">2.1.3</span> (Random scan) Metropolis-within-Gibbs</h3>
<ol style="list-style-type: decimal">
<li>Draw <span class="math inline">\(j \sim \text{Unif}\{1, \ldots, p\}\)</span></li>
<li><ol style="list-style-type: lower-alpha">
<li>Draw <span class="math inline">\(x_{j} \sim q_j\left(\cdot | x^{(t-1)}\right)\)</span> and set <span class="math inline">\(x = \left(x_{1}^{(t-1)}, \ldots, x_j, \ldots, x_{p}^{(t-1)}\right)\)</span></li>
<li>With probability <span class="math inline">\(\min \left\{1, \frac{f(x) \cdot q\left(x^{(t-1)} | x\right)}{f\left(x^{(t-1)}\right) \cdot q\left(x | x^{(t-1)}\right)}\right\}\)</span> set <span class="math inline">\(x^{(t)}=x\)</span>, else set <span class="math inline">\(x^{(t)}=x^{(t-1)}\)</span></li>
</ol></li>
</ol>
</div>
</div>
<div id="meta-analysis-evidence-synthesis-combining-expert-opinion-etc." class="section level2">
<h2><span class="header-section-number">2.2</span> Meta-analysis, evidence synthesis, combining expert opinion etc.</h2>
<div id="multiple-experts" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Multiple Experts</h3>
<p>Notes from Chapter 9 of <span class="citation">(O’Hagan et al. <a href="#ref-o2006uncertain">2006</a>)</span></p>
<ul>
<li>Want to obtain a single distribution which encapsulates the beliefs of several experts</li>
<li>Two approaches
<ul>
<li>Mathematical aggregation: elicit distribution from each expert individually and independently then mathematically combine</li>
<li>Behavioural aggregation: Create an interaction beween the group of experts through which a single distribution is elicited from the group as a whole</li>
</ul></li>
<li>In reference to Markov melding, it seems as though Behavioural approaches are not possible</li>
<li>Each of a group of <span class="math inline">\(n\)</span> experts asked individually for her beliefs about some unknown quantity <span class="math inline">\(\theta\)</span>, eliciting distributions <span class="math inline">\(f_i(\theta)\)</span> for <span class="math inline">\(i = 1, \ldots, n\)</span></li>
<li>Formal Bayesian perspective (DM is a supra-Bayesian): DM begins with his own prior <span class="math inline">\(f(\theta)\)</span> for <span class="math inline">\(\theta\)</span> and has posterior <span class="math inline">\(f(\theta | D)\)</span> after incorporating the experts opinions <span class="math inline">\(D = \{f_1(\theta), \ldots, f_n(\theta)\}\)</span>. This is difficult as DM must construct likelihood <span class="math inline">\(f(D | \theta)\)</span></li>
<li>Simpler and widely used technique is opinion pooling where a consensus distribution <span class="math inline">\(f(\theta)\)</span> is obtained as some function of the individual distributions <span class="math inline">\(\{f_1(\theta), \ldots, f_n(\theta)\}\)</span></li>
<li>Linear opinion pool <span class="math inline">\(f(\theta) \propto \sum_{i=1}^{n} w_i f_i(\theta)\)</span> where the weights <span class="math inline">\(w_i\)</span> sum to one
<ul>
<li>Could weight all experts equally <span class="math inline">\(w_i = 1/n\)</span> for all <span class="math inline">\(i\)</span></li>
<li>Alternatively, give more weight to some expert</li>
<li>Coherent marginalisation</li>
<li>This approach is not externally Bayesian: after recieving new information, updating the priors then pooling the result is not the same as updating the pooled prior</li>
<li>Not consistent with regard to judgements of independence</li>
</ul></li>
<li>Logarithmic opinion pool <span class="math inline">\(f(\theta) \propto \prod_{i=1}^{n} f_i(\theta)^{w_i}\)</span>
<ul>
<li>Again can weight opinions as wishes</li>
<li>Externally Bayesian and consistent about independence</li>
<li>However, unlike linear, no coherent marginalisation (no pooling satisfies both externally Bayesian and coherent marginalisation)</li>
</ul></li>
<li>Product of Experts (special case of logarithmic pooling) <span class="math inline">\(f(\theta) \propto \prod_{i=1}^{n} f_i(\theta)\)</span> <em>To-do: look at Hinton 2002</em></li>
<li>Unlike supra-Bayesian approach, the result of opinion pooling does not represent the actual beliefs of any individual as so may not behave as one would expect a probability distribution to</li>
<li>“In general, while the linear opinion pool has been quite widely used in practice, the logarithmic opinion pool has been largely ignored, perhaps because it is perceived to lead to unrealistically strong aggregated beliefs”</li>
<li>Dictatorial pooling <span class="math inline">\(f(\theta) = f_i(\theta)\)</span> for some <span class="math inline">\(i = 1, \ldots, n\)</span> (not mentioned in book)</li>
<li>Cooke’s method</li>
<li><em>To-do: for more about opinion pooling, look at Clemen</em></li>
</ul>
</div>
</div>
<div id="graphical-models" class="section level2">
<h2><span class="header-section-number">2.3</span> Graphical models</h2>
<div id="bayesian-networks" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Bayesian networks</h3>
<p>Notes from Chapter 7 of <span class="citation">(J. Q. Smith <a href="#ref-smith2010bayesian">2010</a>)</span>.</p>
<div id="relevance-informativeness-and-independence" class="section level4">
<h4><span class="header-section-number">2.3.1.1</span> Relevance, informativeness and independence</h4>
<ul>
<li>Client believes that measurement <span class="math inline">\(X\)</span> is irrelevant for predicting <span class="math inline">\(Y\)</span> given the measurement <span class="math inline">\(Z\)</span>, written <span class="math inline">\(Y \perp X | Z\)</span> if she believes now that once she learns the value of <span class="math inline">\(Z\)</span> then then measurement of <span class="math inline">\(X\)</span> will provide her with no extra useful information with which to predict the value of <span class="math inline">\(Y\)</span>.</li>
<li>In this case, if she is a Bayesian, then she could write her conditional density <span class="math inline">\(p(y | x, z) = p(y | z)\)</span> so that it did not depend on the value of <span class="math inline">\(x\)</span> for all possible values of <span class="math inline">\((x, y, z)\)</span>. Equivalently the joint mass function can be factorised as <span class="math inline">\(p(x, y, z) = p(y | z)p(x | z)p(z)\)</span></li>
<li>Two most important and universally applicable rules:
<ul>
<li>Symmetry <span class="math inline">\(Y \perp X | Z \iff X \perp Y | Z\)</span></li>
<li>Perfect composition <span class="math inline">\(X \perp (Y, Z) | W \iff X \perp Y | (W, Z) \iff X \perp Z | W\)</span></li>
</ul></li>
<li><em>To-do: look at some work of Pearl</em></li>
</ul>
</div>
<div id="bayesian-networks-and-dags" class="section level4">
<h4><span class="header-section-number">2.3.1.2</span> Bayesian networks and DAGs</h4>
<ul>
<li>Bayesian network is a simple and convenient way of representing a factorisation of a joint pdf of a vector of random variables <span class="math inline">\(\mathbf{X} = (X_1, X_2, \ldots, X_n)\)</span>.</li>
<li>Always the case that <span class="math inline">\(p(\mathbf{x}) = p(x_1)p(x_2 | x_1)p(x_3 | x_2, x_1) \times \cdots \times p(x_n | x_1, x_2, \ldots, x_{n-1})\)</span></li>
<li>Often many of the functions <span class="math inline">\(p(x_i | x_1, x_2, \ldots, x_{i-1})\)</span> are explicit functions of components of <span class="math inline">\(X\)</span> whose indices lie in a proper subset <span class="math inline">\(Q_i \subset \{1, 2, \ldots, i - 1\}\)</span> so that <span class="math inline">\(p(x_i | x_1, x_2, \ldots, x_{i-1}) = p(x_i | \mathbf{x}_{Q_i})\)</span></li>
<li>Now <span class="math inline">\(p(\mathbf{x}) = p(x_1)\prod_{i=2}^n p(x_i | \mathbf{x}_{Q_i})\)</span></li>
<li>Let the remainder set <span class="math inline">\(R_i = \{1, 2, \ldots, i - 1\} \ Q_i\)</span> then the above bullet point is equivalent to the set of <span class="math inline">\(n-1\)</span> irrelevance statements <span class="math inline">\(X_i \perp \mathbf{X}_{R_i} | \mathbf{X}_{Q_i}, \, 2 \leq i \leq n\)</span></li>
<li>Definition: A directed acyclic graph (DAG) <span class="math inline">\(\mathcal{G} = (\mathcal{V}, \mathcal{E})\)</span> with set of vertices <span class="math inline">\(\mathcal{V}\)</span> and set of directed edges <span class="math inline">\(\mathcal{E}\)</span> is a directed graph having no directed cycles</li>
<li>Definition: A Bayesian network (BN) on the set of measurements <span class="math inline">\(\{X_1, X_2, \ldots, X_n\}\)</span> is a set of the <span class="math inline">\(n-1\)</span> conditional irrelevance statements together with a DAG <span class="math inline">\(\mathcal{G}\)</span>. The set of vertices <span class="math inline">\(\mathcal{G} = \{X_1, X_2, \ldots, X_n\}\)</span> and a directed edge from <span class="math inline">\(X_i\)</span> to <span class="math inline">\(X_j\)</span> is in <span class="math inline">\(\mathcal{E}\)</span> if and only if <span class="math inline">\(i \in Q_j\)</span></li>
</ul>
</div>
</div>
<div id="factor-graphs" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Factor graphs</h3>
<p>Notes from <span class="citation">(Bishop <a href="#ref-bishop2006pattern">2006</a>)</span>.</p>
<ul>
<li>Factor graphs: ``Factor graphs make this decomposition explicit by introducing additional nodes for the factors themselves in addition to the nodes representing the variables.’’</li>
<li><span class="math inline">\(p(\mathbf{x}) = \prod_s f_s(\mathbf{x}_s)\)</span> where each factor <span class="math inline">\(f_s\)</span> is a function of the corresponding set of variables <span class="math inline">\(x_s\)</span></li>
</ul>
</div>
</div>
<div id="miscellaneous-reading" class="section level2">
<h2><span class="header-section-number">2.4</span> Miscellaneous reading</h2>
<div id="bayesian-approaches-to-random-effects-meta-analysis" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Bayesian approaches to random-effects meta-analysis</h3>
<p>Notes from <span class="citation">(T. C. Smith, Spiegelhalter, and Thomas <a href="#ref-smith1995bayesian">1995</a>)</span></p>
<ul>
<li>Meta analysis, also known as systematic overview, is a statistical procedure in which the results of several independent studies are integrated. Aim is to resolve issues that cannot be concluded from a single study alone</li>
<li><em>Note: <a href="https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/">Gelman blog post about why fixed and random effects terminology is confusing</a></em></li>
<li>Fixed-effect analysis: a common effect across studies is estimated</li>
<li>Random-effects model: a probability model for individual study effects is assumed</li>
<li>“In contrast to the pooled estimate arising from a fixed-effect model, a random-effects meta-analysis assumes that the true effects in each trial are not necessarily equal, but are random observations drawn from some common population distribution”</li>
</ul>
<p>Let <span class="math inline">\(r^C_i\)</span> denote the number of infections in the control group in trial <span class="math inline">\(i\)</span>, arising from <span class="math inline">\(n^C_i\)</span> cases each assumed to have probability <span class="math inline">\(p^C_i\)</span> of developing an infection. Adopt equivalent notation for the treatment group and assume that <span class="math inline">\(\delta_i\)</span> is the true treatment effect on a log-odds scale such that</p>
<p><span class="math display">\[
\delta_i = \mathrm{logit}(p^T_i) - \mathrm{logit}(p^C_i).
\]</span> The “average” infection rate in the <span class="math inline">\(i\)</span>th trial is</p>
<p><span class="math display">\[
\mu_i = \frac{1}{2} (\mathrm{logit}(p^T_i) + \mathrm{logit}(p^C_i)).
\]</span> Individual trial effects are drawn from some Gaussian population with mean <span class="math inline">\(d\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, giving the full model as</p>
<span class="math display">\[\begin{align*}
r^C_i &amp;\sim \text{Binomial}\left(p^C_i, n^C_i\right) \\
r^T_i &amp;\sim \text{Binomial}\left(p^T_i, n^T_i\right) \\
\text{logit}(p^C_i) &amp;= \mu_i - \delta_i/2 \\
\text{logit}(p^T_i) &amp;= \mu_i + \delta_i/2 \\
\delta_i &amp;\sim \text{Normal}(d, \sigma^2)
\end{align*}\]</span>
<ul>
<li>Empirical Bayes’ methods estimate <span class="math inline">\(d\)</span> and <span class="math inline">\(\sigma^2\)</span> from the data by moment-matching, then make inferences conditional on these estimates <span class="math inline">\(\hat d\)</span>, <span class="math inline">\(\hat \sigma^2\)</span> but this does not propigate uncertainty about the estimates. Instead full Bayes puts priors on the unknown parameters</li>
<li>Based on suitable DAG, see Figure 1., the joint distribution is <span class="math inline">\(p(V) = \prod_{v \in V} p(v | \text{pa}(v))\)</span></li>
<li>Used Gibbs sampling (BUGS) to perform inference</li>
</ul>
<div class="figure">
<img src="graphical_model.png" alt="To-do: reproduce this and similar models in Tikz Solid line is stochastic dependence, dashed line is logical dependence" />
<p class="caption"><em>To-do: reproduce this and similar models in Tikz</em> Solid line is stochastic dependence, dashed line is logical dependence</p>
</div>
</div>
<div id="the-statistical-basis-of-meta-analysis" class="section level3">
<h3><span class="header-section-number">2.4.2</span> The statistical basis of meta-analysis</h3>
<p><span class="citation">(Fleiss <a href="#ref-fleiss1993review">1993</a>)</span></p>
<ul>
<li><span class="math inline">\(C\)</span> denote the total number of studies to be analyzed, <span class="math inline">\(c = 1, \ldots, C\)</span>
<ul>
<li>First approach: take these <span class="math inline">\(C\)</span> studies as the only ones of interest</li>
<li>Second approach: take the <span class="math inline">\(C\)</span> studies as a sample from a larger population of studies (fixed vs random set of studies)</li>
</ul></li>
</ul>
</div>
<div id="bayesian-calibration-of-computer-models" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Bayesian calibration of computer models</h3>
<p><span class="citation">(Kennedy and O’Hagan <a href="#ref-kennedy2001bayesian">2001</a>)</span></p>
<ul>
<li>Calibration: the activity of adjusting the unknown rate parameters until the outputs of the model fit the observed data</li>
<li>Bayesian approach with unknown inputs as parameter vector <span class="math inline">\(\theta\)</span></li>
<li>Uncertainties in computer models
<ul>
<li>Parameter uncertainty: uncertainty about the values of some of the computer code inputs</li>
<li>Model inadequacy: no model is perfect. Can’t predict the true value of the process (Note that this is not about stochasticity of the process, define model inadequacy to be difference between true mean value of the real world process and the code output at the true values of inputs)</li>
<li>Residual variability: the real process may not always take the same value for the same repeated inputs. This incompases potential inherent unpredictability, but it may also be that this variation would be eliminated or reduced if only more input conditions were recognised and specified within the model.</li>
<li>Parametric variability: prediction with random parametric inputs (my interpretation)</li>
<li>Observation error: uncertainty about the observations used for calibration</li>
<li>Code uncertainty</li>
</ul></li>
<li>Objective of uncertainty analysis is to study the distribution of the code output that is induced by probability distributions on inputs. Simple Monte Carlo approach: draw configurations of inputs at random from their distribution and run code for each sample input. LHS is better than random sample</li>
<li>Sensitivity analysis aims to characterize how the code output responds to changes in the inputs</li>
<li>Generalised likelihood uncertainty estimation: MC sample from prior on unknown inputs, predictions made using this sample weighted by likelihood</li>
<li>Craig et al. (1992) calibration adopting Bayes linear philosophy (Goldstein)</li>
<li>Raftery et al. (1995) an attempt to combine prior expert opinion on both the calibration parameters and the model output: Bayesian synthesis. Critizised by Wolpert (1995) and Schweder and Hjort (1996), and in a follow-up paper Poole and Raftery (1998) propose Bayesian melding. Neither method explicitly recognises model inadequacy (!!) - related to link parameter discussions?</li>
<li>You can use <span class="math inline">\(f(\cdot) \sim \mathcal{GP}(m(\cdot), k(\cdot, \cdot))\)</span> to model unknown functions as random</li>
</ul>
</div>
<div id="inference-for-deterministic-simulation-models-the-bayesian-melding-approach" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Inference for deterministic simulation models: the Bayesian melding approach</h3>
<p><span class="citation">(Poole and Raftery <a href="#ref-poole2000inference">2000</a>)</span></p>
<ul>
<li>Deterministic simulation model: inputs <span class="math inline">\(\to\)</span> outputs</li>
<li>Easier to build and interpret than a stochastic model</li>
<li>May be very complicated: large number of inputs and outputs, often non-invertible</li>
</ul>
</div>
<div id="combining-models" class="section level3">
<h3><span class="header-section-number">2.4.5</span> Combining Models</h3>
<p>Chapter 14 of <span class="citation">(Bishop <a href="#ref-bishop2006pattern">2006</a>)</span></p>
<p>This chapter is mainly in reference to combining models for prediction (classification and regression) e.g. Bayesian model averaging, committees, boosting. Perhaps there are some connections here which can be made?</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bishop2006pattern">
<p>Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning</em>. springer.</p>
</div>
<div id="ref-fleiss1993review">
<p>Fleiss, JL. 1993. “Review Papers: The Statistical Basis of Meta-Analysis.” <em>Statistical Methods in Medical Research</em> 2 (2). Sage Publications Sage CA: Thousand Oaks, CA: 121–45.</p>
</div>
<div id="ref-kennedy2001bayesian">
<p>Kennedy, Marc C, and Anthony O’Hagan. 2001. “Bayesian Calibration of Computer Models.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (3). Wiley Online Library: 425–64.</p>
</div>
<div id="ref-o2006uncertain">
<p>O’Hagan, Anthony, Caitlin E Buck, Alireza Daneshkhah, J Richard Eiser, Paul H Garthwaite, David J Jenkinson, Jeremy E Oakley, and Tim Rakow. 2006. <em>Uncertain Judgements: Eliciting Experts’ Probabilities</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-poole2000inference">
<p>Poole, David, and Adrian E Raftery. 2000. “Inference for Deterministic Simulation Models: The Bayesian Melding Approach.” <em>Journal of the American Statistical Association</em> 95 (452). Taylor &amp; Francis Group: 1244–55.</p>
</div>
<div id="ref-smith2010bayesian">
<p>Smith, Jim Q. 2010. <em>Bayesian Decision Analysis: Principles and Practice</em>. Cambridge University Press.</p>
</div>
<div id="ref-smith1995bayesian">
<p>Smith, Teresa C, David J Spiegelhalter, and Andrew Thomas. 1995. “Bayesian Approaches to Random-Effects Meta-Analysis: A Comparative Study.” <em>Statistics in Medicine</em> 14 (24). Wiley Online Library: 2685–99.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="markov-melding.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

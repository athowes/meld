# Background

## Monte Carlo

Notes from @johansen2018monte

> "Represent the solution of a problem as a parameter of a hypothetical population, and using a random sequence of numbers to construct a sample of the population, from which statistical estimates of the parameter can be obtained"

* Mainly want to approximate a generic probability density $f(x)$
* If it is possible to sample $X_i \sim f(x)$ for $i = 1,\ldots, N$ then Monte Carlo approximates $f(x)$ by the empirical measure $\widehat{f}(x) = \frac{1}{N} \sum_{i=1}^{N} \delta_{X_i}(x)$
* Can approximate the expectation of any test function $\varphi: \mathcal{X} \to \mathbb{R}$ given by $\mathbb{E}_f [\varphi(X)] := \int \varphi(x) f(x) dx$ as $\int \varphi(x) \widehat{f}(x) dx = \frac{1}{N} \sum_{i=1}^{N} \varphi(X_i)$
* Often it's not possible to sample from $f$, instead sample from a importance density (also called proposal density) $g$ whose support contains that of $f$ 
    + Rejection sampling: only keep samples $X \sim g(x)$ with probability $f(X)/g(X)$
    + Importance sampling: keep all the samples but weight them by the importance ratio $w(X) = f(X)/g(X)$ (preferred to rejection sampling for the most part)
* Accuracy of importance sampling for approximating integrals, for most test functions $\varphi$, depends mostly on the variance of the weights [@liu1996metropolized]. This can be quantified by the effective sample size which can be estimated by

$$
\text{ESS} = \frac{N}{1 + \text{Var}(f(X)/g(X))} \approx \frac{\left(\sum_{i=1}^N w_i \right)^2}{\sum_{i=1}^N w_i^w}
$$

* Importance sampling is roughly as accurate as using an iid sample of size $ESS$ from $f(x)$
* Markov Chain Monte Carlo (MCMC): generate a Markov chain whose stationary distribution is the target distribution $f$

For the following samplers targeting density $f$ and starting with $\mathbf{x}^{(0)} :=\left(x_{1}^{(0)}, \ldots, x_{p}^{(0)}\right)$, iterate for $t = 1, 2, \ldots$

### Metropolis-Hastings Sampler

>
1. Draw $\mathbf{x} \sim q\left(\cdot | \mathbf{x}^{(t-1)}\right)$
2. With probability $\min \left\{1, \frac{f(\mathbf{x}) \cdot q\left(\mathbf{x}^{(t-1)} | \mathbf{x}\right)}{f\left(\mathbf{x}^{(t-1)}\right) \cdot q\left(\mathbf{x} | \mathbf{x}^{(t-1)}\right)}\right\}$ set $\mathbf{x}^{(t)}=\mathbf{x}$, else set $\mathbf{x}^{(t)}=\mathbf{x}^{(t-1)}$

Note that if the proposal $q$ is symmetric (as in random-walk metropolis-hastings) then the acceptance probability simplifies to $\min \left\{1, \frac{f(\mathbf{x})}{f\left(\mathbf{x}^{(t-1)}\right)}\right\}$.

### Gibbs Sampler

Website reference: https://m-clark.github.io/docs/ld_mcmc/#gibbs_sampler

Random-scan Gibbs sampler, for $j = 1, \ldots, p$

> 
1. Draw $j \sim \text{Unif}\{1, \ldots, p\}$
2. Draw $x_j^{(t)} \sim f_{x_j | \mathbf{x}_{-j}}\left(\cdot | x_{1}^{(t-1)}, \ldots, x_{j-1}^{(t-1)}, x_{j+1}^{(t-1)}, \ldots, x_{p}^{(t-1)}\right)$, and set $x_i^{(t)} :=x_i^{(t-1)}$ for all $i \neq j$

Systematic-scan Gibbs sampler, for $j = 1, \ldots, p$

> 
1. Draw $x_j^{(t)} \sim f_{x_j | \mathbf{x}_{-j}}\left(\cdot | x_{1}^{(t)}, \ldots, x_{j-1}^{(t)}, x_{j+1}^{(t-1)}, \ldots, x_{p}^{(t-1)}\right)$

* Introduced by @turchin1971computation and later by @geman1987stochastic (Johansen cites the second as the first proposal)
* Advantage: often efficient when it is appropriate due to 100% accentance rate
* Disadvantage: doesn't work well when there is high correlation between parameters

### (Random scan) Metropolis-within-Gibbs {#mwg}

Website reference: https://m-clark.github.io/docs/ld_mcmc/#metropolis-within-gibbs

>
1. Draw $j \sim \text{Unif}\{1, \ldots, p\}$
2. Draw $x_{j} \sim q_j\left(\cdot | \mathbf{x}^{(t-1)}\right)$ and set $\mathbf{x} = \left(x_{1}^{(t-1)}, \ldots, x_j, \ldots,  x_{p}^{(t-1)}\right)$
3. With probability $\min \left\{1, \frac{f(\mathbf{x}) \cdot q\left(\mathbf{x}^{(t-1)} | \mathbf{x}\right)}{f\left(\mathbf{x}^{(t-1)}\right) \cdot q\left(\mathbf{x} | \mathbf{x}^{(t-1)}\right)}\right\}$ set $\mathbf{x}^{(t)}=\mathbf{x}$, else set $\mathbf{x}^{(t)}=\mathbf{x}^{(t-1)}$

* The original MCMC algorithm, introduced in @metropolis1953equation, predating Gibbs sampling
* Componentwise sampling usually ignores parameter correlation
* Since MWG is a componentwise algorithm, it is most efficient when the acceptance rate of each parameter is 0.44 (rather than 0.234)

## Combining Expert Opinion

### Multiple Experts

Notes from Chapter 9 of @o2006uncertain

* Want to obtain a single distribution which encapsulates the beliefs of several experts
* Two approaches
    + Mathematical aggregation: elicit distribution from each expert individually and independently then mathematically combine
    + Behavioural aggregation: Create an interaction beween the group of experts through which a single distribution is elicited from the group as a whole
* In reference to Markov melding, it seems as though Behavioural approaches are not possible
* Each of a group of $n$ experts asked individually for her beliefs about some unknown quantity $\theta$, eliciting distributions $f_i(\theta)$ for $i = 1, \ldots, n$
* Formal Bayesian perspective (DM is a supra-Bayesian): DM begins with his own prior $f(\theta)$ for $\theta$ and has posterior $f(\theta | D)$ after incorporating the experts opinions $D = \{f_1(\theta), \ldots, f_n(\theta)\}$. This is difficult as DM must construct likelihood $f(D | \theta)$
* Simpler and widely used technique is opinion pooling where a consensus distribution $f(\theta)$ is obtained as some function of the individual distributions $\{f_1(\theta), \ldots, f_n(\theta)\}$
* Linear opinion pool $f(\theta) \propto \sum_{i=1}^{n} w_i f_i(\theta)$ where the weights $w_i$ sum to one
    + Could weight all experts equally $w_i = 1/n$ for all $i$
    + Alternatively, give more weight to some expert
    + Coherent marginalisation
    + This approach is not externally Bayesian: after recieving new information, updating the priors then pooling the result is not the same as updating the pooled prior
    + Not consistent with regard to judgements of independence
* Logarithmic opinion pool $f(\theta) \propto \prod_{i=1}^{n} f_i(\theta)^{w_i}$
    + Again can weight opinions as wishes
    + Externally Bayesian and consistent about independence
    + However, unlike linear, no coherent marginalisation (no pooling satisfies both externally Bayesian and coherent marginalisation)
* Product of Experts (special case of logarithmic pooling) $f(\theta) \propto \prod_{i=1}^{n} f_i(\theta)$ *To-do: look at Hinton 2002*
* Unlike supra-Bayesian approach, the result of opinion pooling does not represent the actual beliefs of any individual as so may not behave as one would expect a probability distribution to
* "In general, while the linear opinion pool has been quite widely used in practice, the logarithmic opinion pool has been largely ignored, perhaps because it is perceived to lead to unrealistically strong aggregated beliefs"
* Dictatorial pooling $f(\theta) = f_i(\theta)$ for some $i = 1, \ldots, n$ (not mentioned in book)
* Cooke's method

### Combining Probability Distributions From Experts in Risk Analysis

Notes from @clemen1999combining

* Expert judgements have been informally used for a long time
* "The mathematical and behavioral approaches we discuss in this paper assume that the experts have ironed out differences in definitions and that they all agree on exactly what is to be forecast or assessed. Practising risk analysts know that these are strong assumptions..." - this could be important in reference to discussion of the definition of link parameter
* "Consulting multiple experts may be viewed as a subjective version of increasing the sample size in an experiment" - combining models is also some kind of way of increasing sample size

### Aggregating Expert Judgement

@french2011aggregating, survey of the current state of the art.

> 
* The Expert Problem: In this a group of experts are consulted by a decision maker who faces a specific real choice and is not a member of the group. She asks the group for their assessment of the probability of an event or for their uncertainty about some quantity or forecast. She must then assimilate their advice into her probability model and feed this into the decision analysis. She alone is responsible and accountable for the decision. In this context the emphasis is on the decision maker learning from the experts.
* The Group Decision Problem: Here the group itself is jointly responsible and accountable for the decision; and they are their own experts. They wish that to the outside world their decision appears rational and, possibly, also fair and democratic. Thus they may wish to combine their judgements in some formal structured way. In this context, the emphasis is on supporting rational, democratic deliberations.
* The Textbook Problem: The group is simply required to give their judgements for others to use in future, as yet undefined circumstances. The emphasis here is on reporting their judgements in a manner that offers the greatest potential for future use.

## Meta-analysis

### The Statistical Basis of Meta-Analysis

@fleiss1993review

* $C$ denote the total number of studies to be analyzed, $c = 1, \ldots, C$
    + First approach: take these $C$ studies as the only ones of interest
    + Second approach: take the $C$ studies as a sample from a larger population of studies (fixed vs random set of studies)
    
### Bayesian Approaches to Random-effects Meta-analysis

Notes from @smith1995bayesian

* Meta analysis, also known as systematic overview, is a statistical procedure in which the results of several independent studies are integrated. Aim is to resolve issues that cannot be concluded from a single study alone
* *Note: [Gelman blog post about why fixed and random effects terminology is confusing]( https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/)*
* Fixed-effect analysis: a common effect across studies is estimated
* Random-effects model: a probability model for individual study effects is assumed
* "In contrast to the pooled estimate arising from a fixed-effect model, a random-effects meta-analysis assumes that the true effects in each trial are not necessarily equal, but are random observations drawn from some common population distribution"

Let $r^C_i$ denote the number of infections in the control group in trial $i$, arising from $n^C_i$ cases each assumed to have probability $p^C_i$ of developing an infection. Adopt equivalent notation for the treatment group and assume that $\delta_i$ is the true treatment effect on a log-odds scale such that

$$
\delta_i = \mathrm{logit}(p^T_i) - \mathrm{logit}(p^C_i).
$$
The "average" infection rate in the $i$th trial is

$$
\mu_i = \frac{1}{2} (\mathrm{logit}(p^T_i) + \mathrm{logit}(p^C_i)).
$$
Individual trial effects are drawn from some Gaussian population with mean $d$ and variance $\sigma^2$, giving the full model as

\begin{align*}
r^C_i &\sim \text{Binomial}\left(p^C_i, n^C_i\right) \\
r^T_i &\sim \text{Binomial}\left(p^T_i, n^T_i\right) \\
\text{logit}(p^C_i) &= \mu_i - \delta_i/2 \\
\text{logit}(p^T_i) &= \mu_i + \delta_i/2 \\
\delta_i &\sim \text{Normal}(d, \sigma^2)
\end{align*}

* Empirical Bayes' methods estimate $d$ and $\sigma^2$ from the data by moment-matching, then make inferences conditional on these estimates $\hat d$, $\hat \sigma^2$ but this does not propigate uncertainty about the estimates. Instead full Bayes puts priors on the unknown parameters
* Based on suitable DAG, see Figure 1., the joint distribution is $p(V) = \prod_{v \in V} p(v | \text{pa}(v))$
* Used Gibbs sampling (BUGS) to perform inference

![Solid line is stochastic dependence, dashed line is logical dependence](files/graphical_model.png)

*To-do: reproduce this and similar models in Tikz*

## Graphical Models

### Bayesian Networks

Notes from Chapter 7 of @smith2010bayesian

#### Relevance, Informativeness and Independence

* Client believes that measurement $X$ is irrelevant for predicting $Y$ given the measurement $Z$, written $Y \perp X | Z$ if she believes now that once she learns the value of $Z$ then then measurement of $X$ will provide her with no extra useful information with which to predict the value of $Y$. 
* In this case, if she is a Bayesian, then she could write her conditional density $p(y | x, z) = p(y | z)$ so that it did not depend on the value of $x$ for all possible values of $(x, y, z)$. Equivalently the joint mass function can be factorised as $p(x, y, z) = p(y | z)p(x | z)p(z)$
* Two most important and universally applicable rules:
    + Symmetry $Y \perp X | Z \iff X \perp Y | Z$
    + Perfect composition $X \perp (Y, Z) | W \iff X \perp Y | (W, Z) \iff X \perp Z | W$
* *To-do: look at some work of Pearl*

#### Bayesian Networks and DAGs

* Bayesian network is a simple and convenient way of representing a factorisation of a joint pdf of a vector of random variables $\mathbf{X} = (X_1, X_2, \ldots, X_n)$.
* Always the case that $p(\mathbf{x}) = p(x_1)p(x_2 | x_1)p(x_3 | x_2, x_1) \times \cdots \times p(x_n | x_1, x_2, \ldots, x_{n-1})$ 
* Often many of the functions $p(x_i | x_1, x_2, \ldots, x_{i-1})$ are explicit functions of components of $X$ whose indices lie in a proper subset $Q_i \subset \{1, 2, \ldots, i - 1\}$ so that $p(x_i | x_1, x_2, \ldots, x_{i-1}) = p(x_i | \mathbf{x}_{Q_i})$
* Now $p(\mathbf{x}) = p(x_1)\prod_{i=2}^n p(x_i | \mathbf{x}_{Q_i})$
* Let the remainder set $R_i = \{1, 2, \ldots, i - 1\} \ Q_i$ then the above bullet point is equivalent to the set of $n-1$ irrelevance statements $X_i \perp \mathbf{X}_{R_i} | \mathbf{X}_{Q_i}, \, 2 \leq i \leq n$
* Definition: A directed acyclic graph (DAG) $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ with set of vertices $\mathcal{V}$ and set of directed edges $\mathcal{E}$ is a directed graph having no directed cycles
* Definition: A Bayesian network (BN) on the set of measurements $\{X_1, X_2, \ldots, X_n\}$ is a set of the $n-1$ conditional irrelevance statements together with a DAG $\mathcal{G}$. The set of vertices $\mathcal{G} = \{X_1, X_2, \ldots, X_n\}$ and a directed edge from $X_i$ to $X_j$ is in $\mathcal{E}$ if and only if $i \in Q_j$

### Factor Graphs

Notes from Chapter 8 of @bishop2006pattern

* Factor graphs: ``Factor graphs make this decomposition explicit by introducing additional nodes for the factors themselves in addition to the nodes representing the variables.''
* $p(\mathbf{x}) = \prod_s f_s(\mathbf{x}_s)$ where each factor $f_s$ is a function of the corresponding set of variables $x_s$
* In a factor graph, there is a node (depicted as usual by a circle) for every variable in the distribution as well as additional nodes (depicted by small squares) for each factor $f_s(\mathbf{x}_s)$ in the joint distribution
* $p(\mathbf{x}) = f_a(x_1, x_2)f_b(x_1, x_2)f_c(x_2, x_3)f_d(x_3)$. Notice that there are two factors $f_a$ and $f_b$ defined over the same set of variables. If the graph was undirected the product of these factors would be lumped together into the same clique potential

![Example factor graph](files/factor_graph.png)

* Factor graphs are bipartite because they consist of two distinct kinds of nodes, and all links go between nodes of opposite type

## Miscellaneous Reading

### Bayesian Calibration of Computer Models

Notes from @kennedy2001bayesian

* Calibration: the activity of adjusting the unknown rate parameters until the outputs of the model fit the observed data
* Bayesian approach with unknown inputs as parameter vector $\theta$
* Uncertainties in computer models
    + Parameter uncertainty: uncertainty about the values of some of the computer code inputs
    + Model inadequacy: no model is perfect. Can't predict the true value of the process (Note that this is not about stochasticity of the process, define model inadequacy to be difference between true mean value of the real world process and the code output at the true values of inputs)
    + Residual variability: the real process may not always take the same value for the same repeated inputs. This incompases potential inherent unpredictability, but it may also be that this variation would be eliminated or reduced if only more input conditions were recognised and specified within the model.
    + Parametric variability: prediction with random parametric inputs (my interpretation)
    + Observation error: uncertainty about the observations used for calibration
    + Code uncertainty
* Objective of uncertainty analysis is to study the distribution of the code output that is induced by probability distributions on inputs. Simple Monte Carlo approach: draw configurations of inputs at random from their distribution and run code for each sample input. LHS is better than random sample
* Sensitivity analysis aims to characterize how the code output responds to changes in the inputs
* Generalised likelihood uncertainty estimation: MC sample from prior on unknown inputs, predictions made using this sample weighted by likelihood
* Craig et al. (1992) calibration adopting Bayes linear philosophy (Goldstein)
* Raftery et al. (1995) an attempt to combine prior expert opinion on both the calibration parameters and the model output: Bayesian synthesis. Critizised by Wolpert (1995) and Schweder and Hjort (1996), and in a follow-up paper Poole and Raftery (1998) propose Bayesian melding. Neither method explicitly recognises model inadequacy (!!) - related to link parameter discussions?
* You can use $f(\cdot) \sim \mathcal{GP}(m(\cdot), k(\cdot, \cdot))$ to model unknown functions as random 

### Inference for Deterministic Simulation Models: the Bayesian Melding Approach

Notes from @poole2000inference

* Deterministic simulation model: inputs $\to$ outputs
* Easier to build and interpret than a stochastic model
* May be very complicated: large number of inputs and outputs, often non-invertible (fixed single set of outputs can be enerated by multiple sets of inputs)
* $M: \theta \to \phi$ with $\theta \in \Theta \subseteq \mathbb{R}^n$ and $\phi \in \Phi \subseteq \mathbb{R}^p$ such that $\phi = M(\theta)$
* $p(\theta, \phi)$ is the joint premodel distribution, which summarises all available information about $\theta$ and $\phi$ except that embodied in the model itself
* Joint distribution of $\theta$ and $\phi$ given the model is the restriction of the premodel distribution to the submanifold $\{(\theta, \phi):\phi = M(\theta)\}$ i.e. $\pi(\theta, \phi) \propto p(\theta, M(\theta))$ if $\phi = M(\theta)$ and zero else.
* $\pi(\theta, \phi)$ is referred to as the postmodel distribution
* ... More in this section about Borel paradox
* Assume that premodel information about inputs is independent of that about outputs then can decompose Bayesian synthesis premodel distribution as $p(\theta, \phi) = p(\theta)p(\phi) \propto q_1(\theta)q_2(\theta)L_1(\theta)L_2(\phi)$ where $q_1(\cdot)$, $q_2(\cdot)$ are the priors and $L_1(\theta) = p(D_\theta|\theta)$, $L_2(\phi) = p(D_\phi|\phi)$ are the likelihoods
* Likelihoods are invariant to reparametrising, so Borel paradox arises due to priors
* $\theta$ is a random variable with density $q_1(\theta)$ so $\phi = M(\theta)$ is also a random variable with induced density $q_1^*(\phi)$. If $M^{-1}$ exists then we can write

$$
q_1^*(\phi) = q_1(M^{-1}(\phi))\det(J(\theta))
$$

* The issue with Bayesian synthesis [@raftery1995inference], noted by @wolpert1995inference, was that it didn't account for the existence of $q_1^*(\phi)$ which is an issue as there are two potentially different priors on $\phi$
* Coherising two priors on the same quantity related to the problem of reaching consensus in the presence of multiple expert opinions (for which there is consideratble attention in the statistics literature)
* Update then pool or pool then update? Should be the same from Bayesain perspective. This is called externally Bayesian by @madansky1964externally
* @genest1986characterization show that logarithmic pooling is the only externally Bayesian pooling operator
* Note that in the Markov melding setting, this does not apply to combining likelihoods with distinct data $Y_m$ (!!)
* How to choose the weights? Somewhat arbitrary
 
### Combining Models

Chapter 14 of @bishop2006pattern

This chapter is mainly in reference to combining models for prediction (classification and regression) e.g. Bayesian model averaging, committees, boosting. Perhaps there are some connections here which can be made?

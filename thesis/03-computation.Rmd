# Computation \label{chapter:comp}

The primary goal in Bayesian computation is to find expectations of functions with respect to the posterior distribution, or in our case the Markov melded posterior given by Equation \eqref{eq:meldpost}.
Many relevant quantities, such as probabilities or risks, can be cast as integrals as the following example demonstrates.

*Example 3.1: Bayesian decision theory*

In assessing developments in evidence-based medicine, @ashby2000evidence argue that a Bayesian approach is the natural framework for decision making under uncertainty.
Suppose $\mathcal{A}$ is the space of possible decisions with elements $a \in \mathcal{A}$ and there exists a utility function $U: \mathcal{A} \to \mathbb{R}^+$ weighing up the drawbacks and benefits of each decision. 
Then, it is clear to see that it is optimal to select the decision $a^\star$ which maximises this utility.
Leaving aside the problem of specifying $U$, most (if not all) of the time the utility also depends on additional variables which we are uncertain about.
If these additional variables are (leadingly) denoted by $\theta \in \Theta$ then our definition of $U$ may be expanded so that $U: \mathcal{A} \times \Theta \to \mathbb{R}^+$.
Now, in order to make well-informed decisions, we must take into account our uncertainty about $\theta$.
Having observed data $y \in \mathcal{Y}$ informative about $\theta$, the distribution which represents this uncertainty is the posterior $p(\theta \, | \, y)$.
Rather than computing utilities, we now must calculate expected utilities.
This is done by integrating out our uncertainty about $\theta$ as follows
\begin{equation}
\mathbb{E}_{p(\theta \, | \, y)}[U(a, \theta)] = \int U(a, \theta) p(\theta \, | \, y) d\theta. \label{eq:bayesdecision}
\end{equation}
The optimal decision now is to select the action maximising this expected utility.
The upshot is that Equation \eqref{eq:bayesdecision} amounts to computing expectations with respect to the posterior. \hfill $\square$

## Monte Carlo methods

Monte Carlo, a general class of simulation-based methods, are a prevailing technique for scalable computation of integrals like that of Equation \eqref{eq:bayesdecision}.
For ease of notation rather than the posterior, we consider a general probability density function $\pi(x)$ where $x \in \mathcal{X}$.
The relevant integral is then
\begin{equation}
\mathbb{E}_\pi[\varphi(x)] = \int \varphi(x) \pi(x) dx
\end{equation}
where $\varphi: \mathcal{X} \to \mathbb{R}$ is an arbitrary test function.

By sampling points independently from the probability density function $X_i \sim \pi(x)$ for $i = 1,\ldots, N$, $\pi(x)$ may be approximated by the empirical distribution
\begin{equation}
\widehat{\pi}(x) = \frac{1}{N} \sum_{i=1}^{N} \delta_{X_i}(x). \label{eq:empirical}
\end{equation}
This facilitates the approximation of expectations by using $\widehat{\pi}(x)$ in place of $\pi(x)$ such that
\begin{equation}
\mathbb{E}_\pi[\varphi(x)] = \int \varphi(x) \pi(x) dx \approx \int \varphi(x) \widehat{\pi}(x) dx = \frac{1}{N} \sum_{i=1}^{N} \varphi(X_i) := \bar \varphi_N. \label{eq:monte}
\end{equation}
By the strong law of large numbers, granted the expectation exists, then the Monte Carlo estimator will converge
\begin{equation}
\lim_{N\to\infty} \bar \varphi_N = \mathbb{E}_\pi[\varphi(x)] 
\end{equation}
almost surely.
In addition, the rate of convergence can be monitored by estimating the variance of the Monte Carlo estimator $\bar \varphi_N$ as
\begin{equation}
\sigma^2_N = \frac{1}{N^2} \sum_{i=1}^{N} \left( \varphi(X_i) - \bar \varphi_N \right)^2,
\end{equation}
and then applying the central limit theorem such that
\begin{equation}
\frac{\bar \varphi_N - \mathbb{E}_\pi[\varphi(x)]}{\sigma_N} \sim \mathcal{N}(0, 1).
\end{equation}

These principles, both the approximation of the empirical distribution via Equation \eqref{eq:empirical} and the convergence of the Monte Carlo estimator, are illustrated in Figure \eqref{fig:monte} for a simple exponential distribution with rate parameter $\lambda = 1$.

```{r dev = "tikz", echo=FALSE, warning=FALSE, fig.height = 7, fig.cap=paste("Above: Emperical distributions generated by samples $X_i \\sim \\text{Exp}(1)$ for $i = 1, \\ldots, N$ for $N$ of varying order of magnitude with exact $\\text{Exp}(1)$ distribution plotted in green. Below: Convergence of the empirical mean, in pink, to the true mean plotted as dashed grey line \\label{fig:monte}")}

cummean <- function(x) cumsum(x) / seq_along(x)

o <- replicate(1, cummean(rexp(1000))) %>%
  as.data.frame() %>%
  mutate(id = row_number()) %>%
  melt("id") %>%
  ggplot(aes(x = id, y = value)) +
    geom_line(alpha = 0.8, col = lightpink) +
    geom_hline(yintercept = 1, lty = "dashed") +
    labs(x = "Sample size", y = "Emperial Mean") +
    guides(col = FALSE) +
    theme(panel.background = element_blank(),
          axis.line = element_line(colour = "grey"))

p1 <- ggplot() +
  stat_function(data = data.frame(x = c(0, 7.5)), aes(x), 
                fun = dexp, n = 100, geom = "line", col = lightgreen, size = 1.5) +
  geom_histogram(data = NULL, aes(x = rexp(100), y= ..density..), 
                 bins = 50, alpha = 0.5, fill = whitesmoke, col = "grey") +
  xlim(c(0, 5)) +
  labs(subtitle = "N = 100", x = "", y = "") +
  theme(panel.background = element_blank(),
        axis.line = element_line(colour = "grey"))

p2 <- ggplot() +
  stat_function(data = data.frame(x = c(0, 7.5)), aes(x), 
                fun = dexp, n = 100, geom = "line", col = lightgreen, size = 1.5) +
  geom_histogram(data = NULL, aes(x = rexp(1000), y= ..density..), 
                 bins = 50, alpha = 0.5, fill = whitesmoke, col = "grey") +
  xlim(c(0, 5)) +
  labs(subtitle = "N = 1000", x = "", y = "") +
  theme(panel.background = element_blank(),
        axis.line = element_line(colour = "grey"))

p3 <- ggplot() +
  stat_function(data = data.frame(x = c(0, 7.5)), aes(x), 
                fun = dexp, n = 100, geom = "line", col = lightgreen, size = 1.5) +
  geom_histogram(data = NULL, aes(x = rexp(10000), y= ..density..), 
                 bins = 50, alpha = 0.5, fill = whitesmoke, col = "grey") +
  xlim(c(0, 5)) +
  labs(subtitle = "N = 10000", x = "", y = "") +
  theme(panel.background = element_blank(),
        axis.line = element_line(colour = "grey"))

p4 <- ggplot() +
  stat_function(data = data.frame(x = c(0, 7.5)), aes(x), 
                fun = dexp, n = 100, geom = "line", col = lightgreen, size = 1.5) +
  geom_histogram(data = NULL, aes(x = rexp(100000), y= ..density..), 
                 bins = 50, alpha = 0.5, fill = whitesmoke, col = "grey") +
  xlim(c(0, 5)) +
  labs(subtitle = "N = 100000", x = "", y = "") +
  theme(panel.background = element_blank(),
        axis.line = element_line(colour = "grey"))

p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)

cowplot::plot_grid(p, o, ncol = 1, rel_heights = c(1, 0.6))
```

## Markov chain Monte Carlo

It is typically not possible to generate independent samples from the relevant distribution directly.
This is especially true for complex models and in high dimensions, which often will be the case for Markov melding.

Markov chain Monte Carlo (MCMC) is a flexible and broad class of algorithms for sampling from such probability distributions which otherwise cannot be accessed.
In MCMC, rather than drawing independent samples, the sample at iteration $i$ depends on that of the previous iteration $i-1$; the result being a a Markov chain of samples.
By careful specification, the stationary distribution of this Markov chain can be set to correspond to the distribution $\pi$ - here referred to as the target distribution.
As a result, if the Markov chain is run until it reaches convergence then it can, more-or-less, be used in place of direct samples from $\pi$.
There are many diagnostic tools which can be used to check if the chain appears to have converged, the simplest being heuristic examination of traceplots which show the positions of the chain over time. 
However, convergence is not something which is possible to prove so discretion must be taken.

Due to the dependence on the previous value, samples from a Markov chain are typically positively correlated, thereby reducing the amount of information each sample contains about $\pi$.
This autocorrelation should be taken into account when calculating the standard error of Monte carlo estimates, see for example @gelman1992inference.
One popular metric of this sort is the effective sample size (ESS) [@robert2013monte] which can be interpreted as the number of independent samples the correlated samples would be equivalent to.

In the following sections we discuss a range of MCMC algorithms and how they might be applied to Markov melding.

### Metropolis-Hastings

\begin{center}
\begin{tcolorbox}[title= Algorithm~\ref*{alg:mh}: Metropolis-Hastings sampler, colback=white, width=0.95\linewidth, sharp corners]
\begin{algorithm}[H]
Target density $\pi$, initialise $x^{(0)}$\;
\For{$i = 1, 2, \ldots, N$}{
  Set current value $x = x^{(i-1)}$\;
  Draw candidate value $x^\star \sim q(\cdot \, | \, x)$\;
  Draw $u \sim \mathcal{U}(0, 1)$\;
  Let $\alpha = \min (1, r)$, where $r = \frac{\pi(x^\star) / q(x^\star \, | \, x)}{\pi(x) / q(x  \, | \, x^\star)}$\;
  \uIf{$\alpha$ > $u$}{
  $x^{(i)}=x^\star$\;
  }
  \uElse{
  $x^{(i)}=x$\;
  }
}
\caption{}
\label{alg:mh}
\end{algorithm}
\end{tcolorbox}
\end{center}

The Metropolis-Hastings (MH) algorithm dates back to foundational work of @metropolis1953equation and @hastings1970monte.
At each iteration $i$, the next step $x^\star$ is suggested according to a user-specified proposal distribution $q(\cdot \, | \, x)$ conditional on the current location $x = x^{(i-1)}$.
Candidate values $x^\star$ are accepted with probability $\alpha$, else the Markov chain remains at the current location $x$. 
The value of the acceptance probability $\alpha$ is calculated by
\begin{align}
\alpha &= \mathbb{P}[x^\star \text{ accepted}] 
= \min (1, r) \nonumber \\
&= \min \left(1, \frac{R(x^\star, x)}{R(x, x^\star)}\right)
= \min \left(1, \frac{\pi(x^\star) / q(x^\star \, | \, x)}{\pi(x) / q(x  \, | \, x^\star)}\right), \label{eq:acceptr}
\end{align}
where $r$ is the ratio of target-to-proposal density ratios $R$ at the candidate $x^\star$ and current $x$ values.

In Bayesian statistics typically the target distribution $\pi$ is such that 
\begin{equation}
\pi(x) = \frac{\gamma(x)}{Z}, \label{eq:normconst}
\end{equation}
where the normalising constant $Z = \int \gamma(x) dx$ is computationally intractable.
To be specific, $\pi$ is the product of the likelihood and prior and $Z$ is the marginal likelihood.
Therefore, it is crucial that Equation \eqref{eq:acceptr} only requires the point-wise evaluation of $\gamma$ and not $\pi$ since $\pi(x)/\pi(z) = \gamma(x)/\gamma(z)$.

The efficiency of MH depends greatly on the user's choice of proposal distribution $q(\cdot \, | \, x)$.
A common option is to consider proposal distributions which are symmetric about the current value $x$, thereby simplifying the acceptance probability $\alpha = \min \left\{1, \pi(x^\star)/\pi(x)\right\}$ since $q(x \, | \, x^\star) = q(x^\star \, | \, x)$.
This algorithm is called random walk Metropolis (RWM).
@roberts1997weak show that, under certain conditions, the acceptance rate for RWM which minimises autocorrelation is 0.44 for one-dimensional proposals tending asymptotically to 0.234 as the dimension increases.

By setting $\pi(x) = p_{\text{meld}}(\phi, \psi_1, \ldots, \psi_M \, | \, y_1, \ldots, y_M)$ the general MH algorithm can be applied to target the Markov melded posterior.
The proposal distribution is then of the form $q(\phi^\star, \psi_1^\star, \ldots, \psi_M^\star \, | \, \phi, \psi_1, \ldots, \psi_M)$, where $(\phi^\star, \psi_1^\star, \ldots, \psi_M^\star)$ are the candidate values and $(\phi, \psi_1, \ldots, \psi_M)$ are the current values of the chain.

The acceptance probability $\alpha = \min (1, r)$ for moves $(\phi, \psi_1, \ldots, \psi_M) \to (\phi^\star, \psi_1^\star, \ldots, \psi_M^\star)$  can be calculated via
\begin{equation}
r=\frac{R(\phi^\star, \psi_1^\star, \ldots, \psi_M^\star, \phi, \psi_1, \ldots, \psi_M)}
       {R(\phi, \psi_1, \ldots, \psi_M, \phi^\star, \psi_1^\star, \ldots, \psi_M^\star)}, \label{eq:acceptprob}
\end{equation}
where $R(\phi^\star, \psi_1^\star, \ldots, \psi_M^\star, \phi, \psi_1, \ldots, \psi_M)$ is the target-to-proposal density ratio
\begin{equation}
R(\phi^\star, \psi_1^\star, \ldots, \psi_{M}^\star, \phi, \psi_1, \ldots, \psi_{M}) 
= \frac{p_{\mathrm{pool}}(\phi^\star) \prod_{m=1}^{M} \frac{p_m(\phi^\star, \psi_m^\star, y_m)}{p_m(\phi^\star)}}{q(\phi^\star, \psi_1^\star, \ldots, \psi_{M}^\star \, | \, \phi, \psi_1, \ldots, \psi_{M})}
\end{equation}
For Markov melding, due to the possible quantity of parameters $(\phi, \psi_1, \ldots, \psi_{M})$, it is likely difficult to find a suitable choice of proposal distribution $q(\phi^\star, \psi_1^\star, \ldots, \psi_{M}^\star \, | \, \phi, \psi_1, \ldots, \psi_{M})$ such that moves are accepted with reasonable probability.

### Metropolis-within-Gibbs

The general MH algorithm ignores the modular structure of the submodels.
As a result both of this structure and the difficulty of full parameter moves, it may be more appealing to update submodel components separately.

Gibbs sampling [@geman1987stochastic] is an MCMC algorithm which updates componentwise.
In fact, Gibbs sampling is a special case of MH where the acceptance rate can be calculated to be identically one.
Returning to the more general notation, suppose that $x$ can be written as a $p$-dimensional vector such that $x = (x_1, \ldots, x_p)$.
In Gibbs sampling at each iteration $i$ only one of the components $x_j$ where $j \in 1, \ldots p$ is updated.
In particular, $x_j$ is sampled from its full conditional distribution, defined as
\begin{equation}
\pi_{X_j \, | \, X_{-j}} (x_j | x_{-j}) = \frac{\pi(x)}{\int \pi(x) dx_j}, \label{eq:fullconditional}
\end{equation}
where the notation $x_{-j}$ refers to the subvector of $x$ excluding the $j$th element.
There are multiple ways of choosing the component $j$ to update at each iteration: it can be chosen uniformly using random-scan Gibbs sampling, or iterated over deterministically using systematic-scan Gibbs sampling.
Having selected a component to update $x_j$, informally speaking Gibbs sampling moves perpendicular to the directions spanned by each of the other components $x_{-j}$.
If components $x_j$ and $x_k$ are say positively correlated then increases in $x_j$ are typically accompanied by increases in $x_k, k \neq j$.
In this situation, Gibbs sampling may not be efficient as it struggles to find the relevant region of probability mass using perpendicular moves.

From a computational point of view, requiring that the full conditionals of $\pi$ are available and can be sampled from is often restrictive.
For Markov melding, the full conditionals of $p_\text{meld}$ may not be available and as a result generic Gibbs sampling is not generally applicable.
Instead, @goudie2019joining propose the use of the Metropolis-within-Gibbs [@muller1991generic] (MWG) algorithm.

\begin{center}
\begin{tcolorbox}[title= Algorithm~\ref*{alg:mwg}: (Random-scan) Metropolis-within-Gibbs sampler, colback=white, width=0.95\linewidth, sharp corners]
\begin{algorithm}[H]
Target density $\pi$, initialise $x^{(0)} :=(x_{1}^{(0)}, \ldots, x_{p}^{(0)})$\;
\For{$i = 1, 2, \ldots, N$}{
  Set current value $x = x^{(i-1)}$\;
  Draw $j \sim \mathcal{U}\{1, \ldots, p\}$\;
  Draw $x^\star_{j} \sim q_j(\cdot \, | \, x)$\;
  Set $x^\star = (x_1, \ldots, x_j^\star, \ldots,  x_p)$\;
  Draw $u \sim \mathcal{U}(0, 1)$\;
  Let $\alpha = \min (1, r)$, where $r = \frac{\gamma(x^\star) / q(x^\star \, | \, x)}{\gamma(x) / q(x  \, | \, x^\star) \cdot }$\;
  \uIf{$\alpha$ > $u$}{
  $x^{(i)}=x^\star$\;
  }
  \uElse{
  $x^{(i)}=x$\;
  }
}
\caption{}
\label{alg:mwg}
\end{algorithm}
\end{tcolorbox}
\end{center}

MWG unifies MH and Gibbs sampling by utilising componentwise MH proposals rather than sampling from the full conditionals exactly.
As such, MWG does not require access to the full conditionals and as a result is more generally applicable.
Of course, if for some index $j$ the full conditional is available then it is a valid MH update and can be used.

As with MH, the user must specify the proposal distributions, in this case $q_j(\cdot \, | \, x_j^{(i-1)})$ for each of the $p$ components.
For random walk type proposals the resulting algorithm known as random walk Metropolis-within-Gibbs (RWM-within-Gibbs). 
This algorithm is studied in the context of optimal scaling by @neal2006optimal who show that, as with RWM, the optimal acceptance rate is 0.44 for one-dimensional proposals again tending to 0.234 for higher dimension as with @roberts1997weak.

Now, to target Equation \eqref{eq:meldpost} using MWG, define the components of $(\phi, \psi_1, \ldots, \psi_M)$ be the link parameter $\phi$ and each of the model specific parameters $\psi_m$, $m = 1, \ldots, M$ respectively as would be expected.
Suppose the initial values $(\phi^{(0)}, \psi_1^{(0)}, \ldots, \psi_M^{(0)})$ are given.

**Model specific parameter updates** 
In Markov melding, it is assumed \eqref{eq:cindep} that the $\psi_m$ are conditionally independent given $\phi$.
Supposing this assumption is reasonable, it would therefore be expected that Gibbs and MWG sampling would be relatively efficient for model specific parameters.
For each of $\psi_m$ for $m = 1, \ldots, M$ define a proposal distribution $q_m(\cdot \, | \, \psi_m)$. 
The target-to-proposal density ratio is then
\begin{align}
&\phantom{=} R(\phi, \psi_1, \ldots, \psi_m^\star, \ldots, \psi_M, \phi, \psi_1, \ldots, \psi_m, \ldots, \psi_M) \nonumber \\
&= p_{\mathrm{pool}}(\phi) \prod_{j=1}^M \frac{p_j(\phi, \psi_j, y_j)}{p_j(\phi)} \frac{1}{q_m(\psi_m^\star \, | \, \psi_m)} \nonumber \\
&= p_{\mathrm{pool}}(\phi) \prod_{j\neq m} \frac{p_j(\phi, \psi_j, y_j)}{p_j(\phi)} \cdot \frac{p_m(\phi, \psi_m^\star, y_m)}{p_m(\phi)} \frac{1}{q_m(\psi_m^\star \, | \, \psi_m)}.
\end{align}
In calculating $r$ via \eqref{eq:acceptprob} factors not dependent on submodel $m$, as well as the pooled prior, cancel leaving
\begin{equation}
r = \frac{p_m(\phi, \psi_m^\star, y_m) \cdot \frac{1}{q_m(\psi_m^\star \, | \, \psi_m)}}{p_m(\phi, \psi_m, y_m) \cdot \frac{1}{q_m(\psi_m \, | \, \psi_m^\star)}}. \label{eq:latentupdate}
\end{equation}
Equation \eqref{eq:latentupdate} precisely corresponds to updating $\psi_m$ conditional on the link parameter $\phi$ for inference performed on the $m$\textsuperscript{th} alone.
With each submodel having been specified as it is, it's reasonable to expect that inference for each submodel individually is tractable via MH.
As such, it is possible to calculate the ratio in Equation \eqref{eq:latentupdate} for each $m = 1, \ldots, M$.

**Link parameter updates**
In contrast to the above, one would expect the link parameter $\phi$ to have some covariance structure with each of the model specific parameters: potentially making link parameter updates relatively inefficient.
For the link parameter $\phi$ define a proposal distribution $q(\cdot \, | \, \phi)$.
The target-to-proposal density ratio is
\begin{equation}
R(\phi, \psi_1, \ldots, \psi_M, \phi^\star, \psi_1, \ldots, \psi_M) = p_{\mathrm{pool}}(\phi^\star) \prod_{m=1}^M \frac{p_m(\phi^\star, \psi_m, y_m)}{p_m(\phi^\star)} \cdot \frac{1}{q(\phi^\star \, | \, \phi)}. \label{eq:linkttp}
\end{equation}
If PoE pooling is used then the marginal distributions of the link parameter cancel, leaving
\begin{align}
R(\phi, \psi_1, \ldots, \psi_M, \phi^\star, \psi_1, \ldots, \psi_M) 
&\propto \prod_{m=1}^M p_m(\phi^\star) \prod_{m=1}^M \frac{p_m(\phi^\star, \psi_m, y_m)}{p_m(\phi^\star)} \cdot \frac{1}{q(\phi^\star \, | \, \phi)} \nonumber \\
&= \prod_{m=1}^M p_m(\phi^\star, \psi_m, y_m) \cdot \frac{1}{q(\phi^\star \, | \, \phi)}.
\end{align}
However, in general, in order to calculate Equation \eqref{eq:linkttp} the prior marginal distributions $p_m(\phi)$ and the closely related $p_{\mathrm{pool}}$ must be evaluated.
If $p_m(\phi)$ is not tractable, @goudie2019joining suggest using an approximation $\hat p_m(\phi)$ found using kernel density estimation with samples drawn from the prior marginal given by Equation \eqref{eq:priormarginal}. 
The samples can be produced by forward Monte Carlo: simulating the statistical relationships (which typically are standard distributions) top-down in the DAG representation of the submodel until the node corresponding to $\phi$ is reached.

In the following example, we demonstrate the use of MCMC for Markov melding two different types of meta-analysis.
For full details of the code used, see the dissertation repository.

*Example 3.2: Metropolis-within-Gibbs for Markov melding*

\begin{figure}
\centering
\begin{tikzpicture}[
      > = stealth, % arrow head style
      shorten > = 1pt, % don't touch arrow head to node
      auto,
      node distance = 3cm, % distance between nodes
      semithick % line style
    ]

    \node[constant] (1) at (0,0){$\kappa_0$};
    \node[constant] (2) at (2,0) {$\upsilon_0$};
    \node[state] (3) at (1,-2) {$\kappa$};
    
    \node[constant] (4) at (4,0){$a$};
    \node[constant] (5) at (6,0) {$b$};
    \node[state] (6) at (5,-2) {$\upsilon$};
    
    \node[state] (7) at (3,-4) {$\delta_i$};
    
    \node[constant] (8) at (7,-2){$\mu_0$};
    \node[constant] (9) at (9,-2) {$\tau_0$};
    \node[state] (10) at (8,-4) {$\mu_i$};
    
    \node[state] (11) at (4.5,-6) {$p_i^C$};
    \node[state] (12) at (6.5,-6) {$p_i^T$};
            
    \node[state] (13) at (4.5,-8) {$r_i^C$};            
    \node[state] (14) at (6.5,-8) {$r_i^T$};
    
    \node[constant] (15) at (0.5,-6) {$N_1$};
    
    \node[above right] at (1.5, -9) {$i = 1, \ldots, n_1$}; 

    \path (1) edge  (3);
    \path (2) edge  (3);
    
    \path (4) edge  (6);
    \path (5) edge  (6);
    
    \path (3) edge  (7);
    \path (6) edge  (7);
    
    \path (8) edge  (10);
    \path (9) edge  (10);
    
    \path (7) edge  (11);
    \path (7) edge  (12);
    \path (10) edge  (11);
    \path (10) edge  (12);
    
    \path (11) edge  (13);
    \path (12) edge  (14);
    \path (15) edge  (13);
    \path (15) edge  (14);
    
    \draw (1.5,-3) -- (9.5,-3) -- (9.5,-9) -- (1.5,-9) -- cycle;
\end{tikzpicture}
\caption{DAG representing Submodel 1}
\label{fig:ex2dag1}
\end{figure}

**Submodel 1** 
Standard meta-analysis usually assumes that either effects are common across studies (fixed-effects) or drawn from a probability distribution (random-effects). @smith1995bayesian present a fully Bayesian approach to random-effects meta-analysis. They use this model to study the effectiveness of a treatment (selective decontamination of the digestive tract) which aims to prevent patients acquiring infections whilst in intensive care units (ICUs). We present an adapted version of the model as follows.

Consider $n_1 = 5$ trials $i = 1, \ldots, n_1$ each with both a control ($C$) and treatment ($T$) group of size $N_1 = 10$.
In trial $i$, individuals within group $j \in \{C, T\}$ are assumed to have independent probability $p_i^j$ of developing an infection. 
The numbers of infections in the control and treatment groups for trial $i$ are $r_i^C$ and $r_i^T$ respectively.
Assume that $\mu_i$ is the average infection rate for the $i$\textsuperscript{th} trial and $\delta_i$ is the true treatment effect, both on the log-odds scale. 
Following @smith1995bayesian, we place an uninformative Gaussian prior on each $\mu_i$, with fixed prior mean $\mu_0 = 0$ and precision $\tau_0 = 0.25$ hyperparameters. 
The prior on each $\delta_i$ is also Gaussian with mean $\kappa$ and precision $\tau$. Uninformative hyperpriors \eqref{eq:hyperprior1} and \eqref{eq:hyperprior2} are placed on both $\kappa$ and $\tau$ with $\kappa_0 = 0$, $\tau = 0.1$ and $a = 3$, $b = 1$. 
Clinical trials aim to assess treatment effectiveness and therefore the mean (log-odds scale) treatment effect $\kappa$ is the parameter of interest. 
The full submodel $p_1(\kappa, \upsilon, \delta, \mu, p^C, p^T, r^C, r^T)$ is then
\begin{align}
\kappa &\sim \mathcal{N}(\kappa_0, \upsilon_0^{-1}), \label{eq:hyperprior1} \\
\upsilon &\sim \text{Gamma}(a, b), \label{eq:hyperprior2} \\
\delta_i &\sim \mathcal{N}(\kappa, \upsilon^{-1}), \\
\mu_i &\sim \mathcal{N}(\mu_0, \tau_0^{-1}), \\
p_i^C &= \frac{e^{\mu_i - \delta_i/2}}{1 + e^{\mu_i - \delta_i/2}}, \; p_i^T = \frac{e^{\mu_i + \delta_i/2}}{1 + e^{\mu_i + \delta_i/2}}, \\
r_i^C &\sim \text{Bin}(N_1, p_i^C), \; r_i^T \sim \text{Bin}(N_1, p_i^T), \quad i = 1, \ldots, n_1,
\end{align}
where the vectors $\delta, \mu, p^C, p^T, r^C, r^T$ are each of length $n_1$, e.g. $\delta = (\delta_1, \ldots, \delta_{n_1})$. 
Observed data for Submodel 1 is $Y_1 = (r^C, r^T)$.
For this example, we forward simulate the observed data $Y_1 = y_1$ (with $N_1 = 10$ and $n_1 = 5$) from $\delta_i \sim \mathcal{N}(-0.25, 4^{-1}), \; \mu_i \sim \mathcal{N}(-1, 2^{-1})$, resulting in $r^C = \{8, 8, 11, 6, 5 \}, \; r^T = \{2, 2, 5, 11, 4 \}$.

The probabilities $p = (p_i^C, p_i^T)$ are an (invertible) deterministic transformation of $(\mu_i, \delta_i)$.
Therefore, each probability has an induced distribution via Equation \eqref{eq:transform}.
Had a prior been specified on $p$ then the situation would have been identical to that of @poole2000inference where there exist multiple priors on parameters in a deterministic simulation model. 
To resolve issues of this sort @goudie2019joining propose using Bayesian melding (introduced in Section \ref{sec:bayesianmelding}) however in this instance we choose not to place a prior on $p$; implicitly accepting the distribution induced by $\mu_i$ and $\delta_i$.
In particular, for $p_i^C$ (a similar statement is true for $p_i^T$) we have the inverse transformation
\begin{equation}
\mu_i - \delta_i/2 = \text{logit}(p_i^C) = \log \frac{p_i^C}{1 - p_i^C},
\end{equation}
with corresponding Jacobian
\begin{equation}
\left|\frac{\delta (\mu_i - \delta_i/2)}{\delta p_i}\right| = \frac{1}{p_i^C(1-p_i^C)}.
\end{equation}
As linear transformations of Gaussian distributions, $\mu_i \pm \delta_i/2$ are Gaussian with mean and variance given by
\begin{align}
\mathbb{E}[\mu_i - \delta_i/2 | \mu_0, \tau_0, \kappa, \upsilon] &= \mu_0 - \kappa/2, \\
\mathbb{E}[\mu_i + \delta_i/2 | \mu_0, \tau_0, \kappa, \upsilon] &= \mu_0 + \kappa/2, \\
\mathbb{V}[\mu_i \pm \delta_i/2 | \mu_0, \tau_0, \kappa, \upsilon] &= \tau_0^{-1} + \upsilon^{-1}/4.
\end{align}
Therefore, defining $(\tau_0^{-1} + \upsilon^{-1}/4)^{-1} = \omega$, the distributions of $p_i^C$ and $p_i^T$ are given by
\begin{align}
p(p_i^C \, | \, \mu_0, \tau_0, \kappa, \upsilon) &= \frac{\omega}{\sqrt{2\pi}} \exp\left(-\frac{\omega}{2}\left(\log \frac{p_i^C}{1 - p_i^C} - (\mu_0 - \kappa/2)\right)^2\right) \frac{1}{p_i^C(1-p_i^C)}, \label{eq:piC} \\
p(p_i^T \, | \, \mu_0, \tau_0, \kappa, \upsilon) &= \frac{\omega}{\sqrt{2\pi}} \exp\left(-\frac{\omega}{2}\left(\log \frac{p_i^T}{1 - p_i^T} - (\mu_0 + \kappa/2)\right)^2\right) \frac{1}{p_i^T(1-p_i^T)}. \label{eq:piT}
\end{align}

Having calculated distributions \eqref{eq:piC} and \eqref{eq:piT} dependence on $(\mu, \delta)$ can be omitted.
Given $(r^C, r^T)$ (and additionally omitting dependence on fixed hyperparameters) the posterior distribution is then
\begin{align}
&\phantom{\propto} p_1(\kappa, \upsilon, p^C, p^T \, | \, r^C, r^T) \nonumber \\
&\propto \prod_{i=1}^{n_1} {N_1\choose r_i^C} {p_i^C}^{r_i^C} (1 - p_i^C)^{N_1 - r_i^C} \frac{\omega}{\sqrt{2\pi}} \exp\left(-\frac{\omega}{2}\left(\log \frac{p_i^C}{1 - p_i^C} - (\mu_0 - \kappa/2)\right)^2\right) \frac{1}{p_i^C(1-p_i^C)} \nonumber \\
&\phantom{\propto} \cdot \prod_{i=1}^{n_1} {N_1\choose r_i^T} {p_i^T}^{r_i^T} (1 - p_i^T)^{N_1 - r_i^T}
\frac{\omega}{\sqrt{2\pi}} \exp\left(-\frac{\omega}{2}\left(\log \frac{p_i^T}{1 - p_i^T} - (\mu_0 + \kappa/2)\right)^2\right) \frac{1}{p_i^T(1-p_i^T)} \nonumber \\
&\phantom{\propto} \cdot \frac{\tau_0}{\sqrt{2\pi}} \exp\left(-\frac{\tau_0}{2}(\mu - \mu_0)^2\right) \cdot \frac{b^a}{\Gamma(a)} \tau^{a-1} \exp(-b \tau) \nonumber \\
% New line
&\propto \prod_{i=1}^{n_1} \{ {p_i^C}^{r_i^C - 1} (1 - p_i^C)^{N_1 - r_i^C - 1} \} \, \omega^{n_1} \exp\left(-\frac{\omega}{2} \sum_{i=1}^{n_1} \left(\log \frac{p_i^C}{1 - p_i^C} - (\mu_0 - \kappa/2)\right)^2\right) \nonumber \\
&\phantom{\propto} \cdot \prod_{i=1}^{n_1} \{ {p_i^T}^{r_i^T - 1} (1 - p_i^T)^{N_1 - r_i^T - 1} \} \, \omega^{n_1} \exp\left(-\frac{\omega}{2} \sum_{i=1}^{n_1} \left(\log \frac{p_i^T}{1 - p_i^T} - (\mu_0 + \kappa/2)\right)^2\right) \nonumber \\
&\phantom{\propto} \cdot \exp\left(-\frac{\upsilon_0}{2}(\kappa - \kappa_0)^2\right) \upsilon^{a-1} \exp(-b \upsilon) \label{eq:ex2post}
\end{align}

Often it is more computationally convenient to work in terms of logarithms as this allows products to be replaced with sums.
In particular, by differencing the logarithm of two parameter settings and then exponentiating the result we obtain acceptance probabilities in a more numerical stable way.
The log-posterior is then
\begin{align}
&\phantom{\propto} \log p(\kappa, \upsilon, p^C, p^T \, | \, r^C, r^T) \nonumber \\
&\propto \sum_{i = 1}^{n_1} \{ (r_i^C - 1) \log p_i^C + (N_1 - r_i^C - 1) \log (1 - p_i^C) \nonumber \\
&\phantom{\propto} + (r_i^T - 1) \log p_i^T + (N_1 - r_i^T - 1) \log (1 - p_i^T) \nonumber \\
&\phantom{\propto} - \frac{\omega}{2} \left(\log \frac{p_i^C}{1 - p_i^C} - (\mu_0 - \kappa/2)\right)^2 - \frac{\omega}{2} \left(\log \frac{p_i^T}{1 - p_i^T} - (\mu_0 + \kappa/2)\right)^2 \} \nonumber \\
&\phantom{\propto} + 2n_1 \omega - \frac{\upsilon_0}{2}(\kappa - \kappa_0)^2 + (a - 1)\log \upsilon - b \upsilon := l_1.
\end{align}

To target the posterior \eqref{eq:ex2post} we use RWM-within-Gibbs.
The initialisation values are chosen to be $0.5$ for each of the probabilities and otherwise chosen according to the prior means $(\kappa^{(0)}, \upsilon^{(0)}) = (\kappa_0, a/b) = (0, 1/3)$.
The proposal distribution for each component is Gaussian with individual componentwise standard deviation parameters tuned to achieve close to the optimal one-dimensional acceptance rate 0.44 (@roberts1997weak note that there is "little value" in finely tuning algorithms to exact values and so the tuning is not done exhaustively - see Table 3.1).

```{r echo=FALSE}
minESS <- minESS(p = 12, eps = .025, alpha = .025)

run <- readRDS("../output/mcmc_smith.Rds")
truth <- readRDS("../output/truth_smith.Rds")

nsim <- dim(run$chain)[1]
thinfactor <- 10000
thin <- run$chain[thinfactor*1:(nsim / thinfactor), ]
```

```{r echo=FALSE}
pC_scale <- c(0.3, 0.25, 0.3, 0.25, 0.2)
pT_scale <- c(0.15, 0.15, 0.25, 0.3, 0.2)
vscale <- c(3, 3.5, pC_scale, pT_scale)

accept <- run$accept[3,]

df <- data.frame(rbind(vscale, accept))
rownames(df) <- c("$\\sigma$", "Acceptance")
colnames(df) <- c("$\\kappa$", "$\\upsilon$", "$p_1^C$", "$p_2^C$", "$p_3^C$", "$p_4^C$", "$p_5^C$", "$p_1^T$", "$p_2^T$", "$p_3^T$", "$p_4^T$", "$p_5^T$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Submodel 1 scaling and resultant acceptance rates for each component") %>%
  kable_styling(position = "center", latex_options = c("scale_down", "hold_position"))
```

To determine an appropriate number of Markov chain samples for the problem at hand one method is to consider the ESS.
To this end, @vats2015multivariate calculate a lower bound on the number of effective samples required to estimate a vector of length $p$ with $100(1 - \alpha)\%$ confidence and a relative tolerance of $\epsilon$. 
Additionally, they define a multivariate ESS which takes into account cross-correlation across the Markov chain components.
Both these methods are implemented in the `R` package `mcmcse` [@mcmcse].

In order to estimate the mean, of length $p = 12$, with $97.5\%$ confidence and a tolerance of $\epsilon = 0.025$ the required number of effective samples is approximately `r round(minESS, digits = -4)`.
Based on a short trial chain, the number of simulations required to achieve this ESS is 2800000 (although this may seem high, at every iteration only one component is proposed and therefore the chain is highly auto-correlated).
That being said, the algorithm is not prohibitively computationally intensive, so we choose to run 5000000 iterations.

Table 3.2 shows that $\kappa$, $\upsilon$ and 6/10 of the probability parameters are estimated such that the truth lies less than one posterior standard deviation from the posterior mean.
Traceplots and histograms for all of the parameters are plotted, for example $\kappa$ and $\upsilon$ in Figure \ref{fig:ex2trace1}.
Based on this output, it would appear that the Markov chains reach convergence.

```{r echo=FALSE}
colvars <- Rfast::colVars(as.matrix(run$chain))
df <- data.frame(rbind(as.numeric(colMeans(run$chain)), truth, sqrt(colvars)))
rownames(df) <- c("PM", "Truth", "PSD")
colnames(df) <- c("$\\kappa$", "$\\upsilon$", "$p_1^C$", "$p_2^C$", "$p_3^C$", "$p_4^C$", "$p_5^C$", "$p_1^T$", "$p_2^T$", "$p_3^T$", "$p_4^T$", "$p_5^T$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Submodel 1 posterior mean (PM), true value and posterior standard deviation (PSD) for each component") %>%
  kable_styling(position = "center", latex_options = c("scale_down", "hold_position"))
```

```{r dev = "tikz", echo=FALSE, warning=FALSE, fig.height = 3.5, fig.cap=paste("Submodel 1 posterior traceplots and histograms for the parameters $\\kappa$ and $\\upsilon$, with truth shown on the histogram as a dashed black line (as it will be for all histograms to follow). Similar plots for the ten other probability parameters are presented in Appendix \\ref{app:A}. Note that for this, and all subsequent, traceplots the chains have first been thinned for graphical display reasons \\label{fig:ex2trace1}")}
trace_hist <- function(num, latex, mycol = darkblue) {
  p1 <- ggplot(thin, aes_string(y = paste0("V", num), x = 1:(nsim/thinfactor))) +
    geom_line(alpha = 0.8, col = "grey") +
    labs(x = "Iterations", y = latex) +
    scale_x_continuous(breaks = c(0, (nsim/(2*thinfactor)), (nsim/thinfactor)), labels = c(0, (nsim/2), nsim)) +
    theme(panel.background = element_blank(),
          axis.line = element_line(colour = "grey"),
          plot.margin = unit(c(5.5, 7, 5.5, 5.5), "points"))
  
  p2 <- ggplot(run$chain, aes_string(x = paste0("V", num))) +
    geom_histogram(aes(y = (..count..)/sum(..count..)), 
                   alpha = 0.7, bins = 30, 
                   fill = whitesmoke, col = mycol) +
    labs(x = latex, y = "Proportion") +
    geom_vline(xintercept = truth[num], colour = "black", linetype = "longdash") +
    theme(panel.background = element_blank(),
          axis.line = element_line(colour = "grey"))
  return(cowplot::plot_grid(p1, p2, ncol = 2))
}

p1 <- trace_hist(1, "$\\kappa$")
p2 <- trace_hist(2, "$\\upsilon$")

cowplot::plot_grid(p1, p2, ncol = 1)
```

\newpage

\begin{figure}
\centering
\begin{tikzpicture}[
      > = stealth, % arrow head style
      shorten > = 1pt, % don't touch arrow head to node
      auto,
      node distance = 3cm, % distance between nodes
      semithick % line style
    ]

    \node[constant] (1) at (0,0){$\kappa_0$};
    \node[constant] (2) at (2,0) {$\upsilon_0$};
    \node[state] (3) at (1,-2) {$\kappa$};
    
    \node[constant] (4) at (4,0){$\lambda_0$};
    \node[constant] (5) at (6,0) {$\gamma_0$};
    \node[state] (6) at (5,-2) {$\lambda$};
    
    \node[state] (7) at (2,-4) {$q^C$};
    \node[state] (8) at (4,-4) {$q^T$};
    
    \node[state] (9) at (2,-6) {$s_i^C$};
    \node[state] (10) at (4,-6) {$s_i^T$};
    
    \node[constant] (11) at (0,-4) {$N_2$};
    
    \node[above right] at (1, -7.25) {$i = 1, \ldots, n_2$}; 

    \path (1) edge  (3);
    \path (2) edge  (3);
    
    \path (4) edge  (6);
    \path (5) edge  (6);
    
    \path (3) edge  (7);
    \path (6) edge  (7);
    \path (3) edge  (8);
    \path (6) edge  (8);
    
    \path (7) edge  (9);
    \path (8) edge  (10);
    \path (11) edge  (9);
    \path (11) edge  (10);
    
    
    \draw (1,-5) -- (5,-5) -- (5,-7.25) -- (1,-7.25) -- cycle;
\end{tikzpicture}
\caption{DAG representing Submodel 2}
\label{fig:ex2dag2}
\end{figure}

**Submodel 2**
Suppose that a second collection of $n_2 = 10$ trials of the same treatment have been conducted in a different region with treatment and control groups of size $N_2 = 15$.
It is believed that there is less variability in the quality of hospitals and therefore that a fixed-effects meta-analysis is the most appropriate model for this data.

The full submodel $p_2(\kappa, \lambda, q^C, q^T, s^C, s^T)$ is given by
\begin{align}
\kappa &\sim \mathcal{N}(\kappa_0, \upsilon_0^{-1}),  \\
\lambda &\sim \mathcal{N}(\lambda_0, \gamma_0^{-1}), \\
q^C &= \frac{e^{\lambda - \kappa/2}}{1 + e^{\lambda - \kappa/2}}, \; q^T = \frac{e^{\lambda + \kappa/2}}{1 + e^{\lambda + \kappa/2}}, \\
s_i^C &\sim \text{Bin}(N_2, q^C), \; s_i^T \sim \text{Bin}(N_2, q^T), \quad i = 1, \ldots, n_2,
\end{align}
where $s^T$ and $s^C$ are vectors of length $n_2$ such that the observed data for this submodel is $Y_2 = (s^T, s^C)$.
This submodel has a similar structure to Submodel 1, the difference informally being that the plate has been moved down only to include the trial outcomes.

Assume the authors of this study have more informative prior beliefs (following a subjective Bayesian approach) about $\kappa$, setting $\kappa_0 = -0.1$ and $\upsilon_0 = 0.5$.
The prior on $\lambda$ is similar to that of each of the $\mu_i$ in Submodel 1, such that $\lambda_0 = 0$ and $\gamma_0 = 0.25$.

As with the first submodel, we forward simulate observed data by setting $\kappa = -0.25$ and $\lambda = -1$. The observed data $Y_2 = y_2$ is then $s^C = \{3, 4, 5, 7, 3, 7, 7, 5, 5, 2 \}$ and $s^C = \{3, 4, 5, 7, 3, 7, 7, 5, 5, 2 \}$.

To facilitate Markov melding, inference about the underlying parameters $\kappa$ and $\lambda$ is conducted rather than the probabilities $q^C$ and $q^T$ - which typically would seem to be the more natural option. 
Indeed for a fixed effects meta-analysis more generally it would likely be preferable to directly place priors on the probabilities (for example a Beta prior would be conjugate to the Binomial likelihood).
Setting this fact aside, the posterior distribution given $(s^C, s^T)$ is
\begin{align}
&\phantom{\propto} p_2(\kappa, \lambda \, | \, s^C, s^T) \nonumber \\
&\propto \prod_{i = 1}^{n_2} {N_2\choose s_i^C} \left(\frac{e^{\lambda - \kappa/2}}{1 + e^{\lambda - \kappa/2}}\right)^{s_i^C} \left(\frac{1}{1 + e^{\lambda - \kappa/2}}\right)^{N_2 - s_i^C} \left(\frac{1}{1 + e^{\lambda - \kappa/2}}\right)^2 \nonumber \\
&\phantom{\propto} \cdot \prod_{i = 1}^{n_2} {N_2\choose s_i^T} \left(\frac{e^{\lambda + \kappa/2}}{1 + e^{\lambda + \kappa/2}}\right)^{s_i^T} \left(\frac{1}{1 + e^{\lambda + \kappa/2}}\right)^{N_2 - s_i^T} \left(\frac{1}{1 + e^{\lambda + \kappa/2}}\right)^2 \nonumber \\
&\phantom{\propto} \cdot \frac{\upsilon_0}{\sqrt{2\pi}} \exp\left(-\frac{\upsilon_0}{2}(\kappa - \kappa_0)^2\right) \cdot \frac{\gamma_0}{\sqrt{2\pi}} \exp\left(-\frac{\gamma_0}{2}(\lambda - \lambda_0)^2\right) \nonumber \\
% End line
&\propto \left(\frac{e^{\lambda - \kappa/2}}{1 + e^{\lambda - \kappa/2}}\right)^{\sum_{i = 1}^{n_2} s_i^C} \left(\frac{1}{1 + e^{\lambda - \kappa/2}}\right)^{2 + n_2N_2 - \sum_{i = 1}^{n_2} s_i^C} \nonumber \\
&\phantom{\propto}  \cdot \left(\frac{e^{\lambda + \kappa/2}}{1 + e^{\lambda + \kappa/2}}\right)^{\sum_{i = 1}^{n_2} s_i^T} \left(\frac{1}{1 + e^{\lambda + \kappa/2}}\right)^{2 + n_2N_2 - \sum_{i = 1}^{n_2} s_i^T} \nonumber \\
&\phantom{\propto} \cdot  \exp\left(-\frac{\upsilon_0}{2}(\kappa - \kappa_0)^2\right) \cdot \exp\left(-\frac{\gamma_0}{2}(\lambda - \lambda_0)^2\right), \label{eq:ex2post2}
\end{align}
where again transformation of variables is used (both of which with Jacobians $(1 + e^{\lambda - \kappa/2})^{-2}$).
The log posterior is
\begin{align}
&\phantom{\propto} \log p(\kappa, \lambda \, | \, s^C, s^T) \nonumber \\
&\propto \sum_{i = 1}^{n_2} s_i^C \log \left(\frac{e^{\lambda - \kappa/2}}{1 + e^{\lambda - \kappa/2}}\right) + (2 + n_2N_2 - \sum_{i = 1}^{n_2} s_i^C) \log \left(\frac{1}{1 + e^{\lambda - \kappa/2}}\right) \nonumber \\
&\phantom{\propto} + \sum_{i = 1}^{n_2} s_i^T \log \left(\frac{e^{\lambda + \kappa/2}}{1 + e^{\lambda + \kappa/2}}\right) + (2 + n_2N_2 - \sum_{i = 1}^{n_2} s_i^T) \log \left(\frac{1}{1 + e^{\lambda + \kappa/2}}\right) \nonumber \\
&\phantom{\propto} - \frac{\upsilon_0}{2}(\kappa - \kappa_0)^2  - \frac{\gamma_0}{2}(\lambda - \lambda_0)^2 := l_2.
\end{align}

To target Equation \eqref{eq:ex2post2} we again use the RWM-within-Gibbs algorithm with acceptance rates tuned to 0.44.
The initialisation values are chosen based on the a-priori means $(\kappa^{(0)}, \lambda^{(0)}) = (0.1, 0)$.
The number of samples used (1000000) is based on similar considerations to that of Submodel 1 (as we are only estimating a $p = 2$ dimensional mean the required effective samples is much lower).
The resulting traceplots, histograms and posterior summaries are shown in Figure \ref{fig:ex2submodel2} and Table 3.4 respectively.
Once again the MCMC output looks free from any significant problems.
Both $\kappa$ and $\lambda$ are accurately recovered: well within posterior mean plus or minus one posterior standard deviation.

```{r echo=FALSE}
run <- readRDS("../output/mcmc_fixed.Rds")
truth <- readRDS("../output/truth_fixed.Rds")

nsim <- dim(run$chain)[1]
thinfactor <- 1000
thin <- run$chain[thinfactor*1:(nsim / thinfactor), ]
```

```{r echo=FALSE}
vscale <- c(0.55, 0.3)
accept <- run$accept[3,]

df <- data.frame(rbind(vscale, accept))

rownames(df) <- c("$\\sigma$", "Acceptance")
colnames(df) <- c("$\\kappa$", "$\\lambda$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Submodel 2 scaling and acceptance rate for $\\kappa$ and $\\lambda$") %>%
  kable_styling(latex_options = c("hold_position"))
```

```{r echo=FALSE}
colvars <- Rfast::colVars(as.matrix(run$chain))

df <- data.frame(rbind(colMeans(run$chain), truth, sqrt(colvars)))

rownames(df) <- c("PM", "Truth", "PSD")
colnames(df) <- c("$\\kappa$", "$\\lambda$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Submodel 2 posterior mean (PM), true value and posterior standard deviation (PSD) for $\\kappa$ and $\\lambda$") %>%
  kable_styling(latex_options = c("hold_position"))
```

```{r dev = "tikz", echo=FALSE, warning=FALSE, fig.height = 3.5, fig.cap=paste("Submodel 2 posterior traceplots and histograms for the parameters $\\kappa$ and $\\lambda$ \\label{fig:ex2submodel2} ")}
p1 <- trace_hist(1, "$\\kappa$", mycol = darkgreen)
p2 <- trace_hist(2, "$\\lambda$", mycol = darkgreen)

cowplot::plot_grid(p1, p2, ncol = 1)
```

\newpage

**Melded model**
By Equation \eqref{eq:meldpost}, the Markov melded posterior is 
\begin{align}
&\phantom{\propto} p_{\text{meld}}(\kappa, \upsilon, p^C, p^T, \lambda \, | \, r^C, r^T, s^C, s^T) \nonumber \\
&\propto p_{\text{pool}}(\kappa) \frac{p_1(\kappa, \upsilon, p^C, p^T \, | \, r^C, r^T)}{p_1(\kappa)} \frac{p_2(\kappa, \upsilon \, | \, s^C, s^T)}{p_2(\kappa)}. \label{eq:ex2melda}
\end{align}

For computational simplicity, PoE pooling $p_{\text{pool}}(\kappa) \propto p_1(\kappa) p_2(\kappa)$ is chosen such that Equation \eqref{eq:ex2melda} simplifies to
\begin{equation}
p_{\text{meld}}(\kappa, \upsilon, p^C, p^T, \lambda \, | \, r^C, r^T, s^C, s^T)
\propto p_1(\kappa, \upsilon, p^C, p^T \, | \, r^C, r^T) p_2(\kappa, \upsilon \, | \, s^C, s^T). \label{eq:ex2meldb}
\end{equation}
Taking the logarithm, we have that the log posterior is simply a sum of the submodel log posteriors, $l_1$ and $l_2$
\begin{align}
&\phantom{\propto} \log p_{\text{meld}}(\kappa, \upsilon, p^C, p^T, \lambda \, | \, r^C, r^T, s^C, s^T) \nonumber \\
&\propto \log p_1(\kappa, \upsilon, p^C, p^T \, | \, r^C, r^T) + \log p_2(\kappa, \upsilon \, | \, s^C, s^T) \nonumber \\
&\propto l_1 + l_2.
\end{align}

To target Equation \eqref{eq:ex2meldb} we use 5000000 iterations of RWM-within-Gibbs with each component tuned to 0.44 acceptance rate.
Each parameter is initialised as before, either based on a-priori means or 0.5 for probabilities.

```{r echo=FALSE}
run <- readRDS("../output/mcmc_meld.Rds")
truth <- readRDS("../output/truth_meld.Rds")

nsim <- dim(run$chain)[1]
thinfactor <- 10000
thin <- run$chain[thinfactor*1:(nsim / thinfactor), ]
```

```{r echo=FALSE}
vscale <- c(0.6, 3.5, 0.3, 0.25, 0.3, 0.25, 0.2, 0.15, 0.15, 0.25, 0.3, 0.2, 0.4)
accept <- run$accept[3,]

df <- data.frame(rbind(vscale, accept))

rownames(df) <- c("$\\sigma$", "Acceptance")
colnames(df) <- c("$\\kappa$", "$\\upsilon$", "$p_1^C$", "$p_2^C$", "$p_3^C$", "$p_4^C$", "$p_5^C$", 
                  "$p_1^T$", "$p_2^T$", "$p_3^T$", "$p_4^T$", "$p_5^T$", "$\\lambda$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Melded model scaling and acceptance rate for each component") %>%
  kable_styling(position = "center", latex_options = c("scale_down", "hold_position"))
```

```{r echo=FALSE}
colvars <- Rfast::colVars(as.matrix(run$chain))

df <- data.frame(rbind(colMeans(run$chain), truth, sqrt(colvars)))

rownames(df) <- c("PM", "Truth", "PSD")
colnames(df) <- c("$\\kappa$", "$\\upsilon$", "$p_1^C$", "$p_2^C$", "$p_3^C$", "$p_4^C$", "$p_5^C$", 
                  "$p_1^T$", "$p_2^T$", "$p_3^T$", "$p_4^T$", "$p_5^T$", "$\\lambda$")

kable(round(df, 3), booktabs = TRUE, escape = FALSE, caption = "Melded model posterior mean (PM), true value and posterior standard deviation (PSD) for each component") %>%
  kable_styling(position = "center", latex_options = c("scale_down", "hold_position"))
```

```{r dev = "tikz", echo=FALSE, warning=FALSE, fig.height = 5.25, fig.cap=paste("Melded model posterior traceplots and histograms for the parameters $\\kappa$, $\\upsilon$ and $\\lambda$. As with Submodel 1, plots for the other parameters are presented in Appendix \\ref{app:A}")}
p1 <- trace_hist(1, "$\\kappa$", mycol = darkpink)
p2 <- trace_hist(2, "$\\upsilon$", mycol = darkpink)
p3 <- trace_hist(13, "$\\lambda$", mycol = darkpink)

cowplot::plot_grid(p1, p2, p3, ncol = 1)
```

```{r echo=FALSE}
smith <- as.numeric(readRDS("../output/means_smith.Rds"))
fixed <- as.numeric(readRDS("../output/means_fixed.Rds"))
meld <- as.numeric(readRDS("../output/means_meld.Rds"))
```

The posterior means for $\kappa$ are -0.314 (Submodel 1), -0.221 (Submodel 2) and -0.224 (melded model) respectively.
This result is not due to Monte carlo error: as well as the ESS considerations, 100 replications of each simulation gives maximum and minimum posterior means for $\kappa$ to be [`r round(min(smith), 3)`, `r round(max(smith), 3)`] (Submodel 1), [`r round(min(fixed), 3)`, `r round(max(fixed), 3)`] (Submodel 2) and [`r round(min(meld), 3)`, `r round(max(meld), 3)`] (melded model).
Notably, the melded model estimate is far closer to that of Submodel 2.
This is relatively unsurprising since Submodel 2 is substantially more informative than Submodel 1.
Firstly, the sample size is larger: $2N_1n_1 = 100$ patients in $Y_1$ compared with $2N_2n_2 = 300$ patients in $Y_2$.
Additionally, due to the random-effects (remembering that the data is simulated) there is more variation in the Submodel 1 data and thus the signal is weaker than for the fixed-effects Submodel 2.

The fitted submodel specific parameters in the melded model (a little disappointingly) appear to be essentially the same as when fitting each of the submodels alone.
Just as with Submodel 1, the same 6/10 intervals generated by posterior mean plus or minus one posterior standard deviation contain the truth. \hfill $\square$

Having introduced and demonstrated a successful method for Markov melding inference, in the final part of this chapter we discuss one further algorithm extending the MWG approach.

## Sequential Monte Carlo

In some situations, where the submodels are complex, it may be challenging (or computationally inefficient) to directly sample from the full Markov melded posterior using MWG.
@goudie2019joining therefore propose a sequential approach, in which information from the submodels is added step-by-step.
At a high-level, it is an example of Sequential Monte Carlo (SMC) which we outline the connection to here.

Consider a probability density function $\pi(x)$ as before defined on the state space $\mathcal{X}$.
Following @lindsten2017divide, if $\mathcal{X}$ is a product space it may be decomposed into a Cartesian product of subspaces according to
\begin{equation}
\mathcal{X} := \mathcal{X}_T = \widetilde{\mathcal{X}}_1 \times \widetilde{\mathcal{X}}_2 \times \cdots \times \widetilde{\mathcal{X}}_T. \label{eq:seqdecomp}
\end{equation}
Elements $x \in \mathcal{X}$ in the product space may be written as $x := x_T = (\widetilde{x}_1, \ldots, \widetilde{x}_T)$. 
Both the elements of the subspaces and the subspaces themselves are denoted with tildes, so that $\widetilde{x}_t \in \widetilde{\mathcal{X}}_t,$ for $1 \leq t \leq T$. 
A sequence of auxiliary probability distributions $\pi_1, \ldots \pi_T$ can be defined on the spaces $\mathcal{X}_t$ of lower dimension $1 \leq t \leq T$ than $\mathcal{X}_T$.
$\pi_t(x_t) := \pi_t(\widetilde{x}_1, \cdots, \widetilde{x}_t)$ for $t = 1, \ldots, T$.
The final auxiliary distribution is chosen to coincide with the target distribution, such that
\begin{equation}
\pi = \pi_T \label{eq:seqfinal}.
\end{equation}
Collections of auxiliary distributions with the two properties, \eqref{eq:seqdecomp} and \eqref{eq:seqfinal}, are called a sequential decomposition of the target distribution $\pi$.

Sequential Monte Carlo (SMC) methods are a general class of Monte Carlo algorithms designed for situations where sequential decompositions are applicable.
The distributions $\pi_1, \pi_2, \cdots, \pi_T = \pi$ are approximated sequentially, allowing information from previous iterations to inform the sampling strategy as it proceeds.

### Multi-stage Metropolis-within-Gibbs

\begin{figure}
\centering
\begin{tikzpicture}
    \node (1) at (0,0)   [label=below:{$p_{\text{meld,}1}$}, point];
    \node (2) at (1.5,0) [label=below:{$p_{\text{meld,}2}$}, point];
    \node (3) at (3,0)   [] {$\cdots$};
    \node (4) at (4.5,0) [label=below:{$p_{\text{meld,}M}$}, point];
    
    \path (1) edge (2);
    \path (2) edge (3);
    \path (3) edge (4);
\end{tikzpicture}
\caption{Computational flow of the multi-stage MWG sampler for Markov melding. Stages labeled with target auxiliary distribution. Adapted to Markov melding context from Lindsten et al. (2017)}
\label{fig:compflow}
\end{figure}

Define $(\phi, \psi_1, \ldots, \psi_M) = \theta_M = \theta \in \Theta$, then the full parameter space $\Theta$ may be decomposed such that $\Theta = \Phi \times \Psi_1 \times \cdots \times \Psi_M$. 
Define the sequence of subspaces $\Theta_\ell = \Phi \times \Psi_1 \times \cdots \times \Psi_m$ with respective elements $\theta_\ell = (\phi, \psi_1, \ldots, \psi_\ell)$ for $\ell = 1, \ldots, M$. 
The subspaces are of increasing dimension such that $\Theta_1 \subseteq \cdots \subseteq \Theta_\ell \subseteq \cdots \subseteq \Theta_M$ with the final subspace $\Theta_M = \Theta$.

It remains to construct a sequence of auxiliary probability distributions $p_{\text {meld,}l}$ defined on the subspaces $\Theta_\ell$ such that the $M$\textsuperscript{th} distribution coincides with the posterior
\begin{equation}
p_{\text {meld,}M}(\theta_M) = p_{\text {meld,}M}(\phi, \psi_1, \ldots, \psi_M) = p_{\text{meld}}(\phi, \psi_1, \ldots, \psi_M \, | \, y_1, \ldots, y_M) \label{eq:Mthstage}
\end{equation}
The posterior \eqref{eq:meldpost} includes a product of the submodel posteriors $p_m(\phi, \psi_m \, | \, y_m)$ and
conditional on $\phi$, the $m$\textsuperscript{th} submodel is the only source of information about $\psi_m$.
It therefore seems reasonable that when $\Psi_m \subseteq \Theta_\ell$ this information $p_m(\phi, \psi_m \, | \, y_m)$ about $\psi_m$ is included in the auxiliary probability distribution.

On the other hand, informally speaking, information about the link parameter is $\phi$ is dispersed across the $M$ submodels.
For this reason there is flexibility about how the auxiliary distributions should be defined to take this into account.
This flexibility can be encapsulated by the possible factorisations of the pooled prior
\begin{equation}
p_{\text{pool}}(\phi) = \prod_{m=1}^{M} p_{\text{pool,}m}(\phi). \label{eq:factorpp}
\end{equation}
Two example factorisations are $p_{\text{pool,}m}(\phi) = p_{\text{pool}}(\phi)^{1/M}$ and $p_{\text{pool,}m}(\phi) = p_m(\phi)$.

Therefore, the $\ell$\textsuperscript{th} stage posterior over the parameters $\theta_\ell \in \Theta_\ell$ is defined to be
\begin{equation}
p_{\text{meld,}l}(\theta_\ell \, | \, y_1, \ldots, y_\ell) \propto \prod_{m=1}^\ell\left(\frac{p_m(\phi, \psi_m, y_m)}{p_m(\phi)} p_{\mathrm{pool}, m}(\phi)\right)
\end{equation}
where indeed Equation \eqref{eq:Mthstage} holds.

To sample from this sequence of auxiliary distributions, @goudie2019joining generalise a previous two-stage computational approach of @lunn2013fully.
With the introduction of each additional parameter, the relevant Markov chains may be initialised as before at the corresponding elements of $(\phi^{(0)}, \psi_1^{(0)}, \ldots, \psi_M^{(0)})$.

**Stage 1.** 
For the first stage, the auxiliary target distribution is the 1\textsuperscript{st} stage posterior $p_{\text {meld,}1}(\phi, \psi_{1} \, | \, y_{1})$. Samples $(\phi^{(h, 1)}, \psi_1^{(h, 1)})$ for $h=1, \ldots, H_1$ from this distribution can typically be drawn using standard MCMC methods such as MWG. 
If $p_{\text{pool,}1}(\phi) = p_1(\phi)$ then the first stage posterior corresponds to the standard posterior $p_m(\phi, \psi_m \, | \, y_m)$. 
This may present computational advantages as often a given submodel may have been fit and samples will be already available. This factor may motivate setting the first submodel to be the most computational intensive submodel for which samples are available.

**Stage $\ell$.** 
Following stage $\ell-1$, samples $(\theta^{(h, \ell-1)})$ for $h = 1, \ldots, H_{\ell-1}$ from the $(\ell-1)$\textsuperscript{th} stage posterior $p_{\text {meld,}\ell-1}(\theta_{\ell-1} \, | \, y_{1}, \ldots, y_{\ell-1})$ are available. 
In stage $\ell$ a MWG sampler targeting $p_{\text{meld,}l}(\theta_{\ell-1}, \psi_\ell \, | \, y_1, \ldots, y_\ell)$ on the space $\Theta_\ell = \Theta_{\ell - 1} \times \Psi_\ell$ is constructed. 

Keeping $\theta_{\ell - 1}$ fixed, the parameter $\psi_m$ is updated as usual using a Metropolis-Hastings step. 
This chain can be initialised at $\psi_m^{(0)}$. 
The target-to-proposal density ratio is equivalent, with respect to the calculation of $r$ as in Equation \eqref{eq:latentupdate}, to
\begin{equation}
R(\theta_{\ell - 1}, \psi_\ell^\star, \theta_{\ell - 1}, \psi_\ell) = p_\ell(\phi, \psi_\ell^\star, y_\ell) \cdot \frac{1}{q(\psi_\ell^\star \, | \, \psi_\ell)}
\end{equation}

Now, to update the parameters $\theta_{\ell - 1}$ the empirical distribution generated by the draws $(\theta^{(h, \ell-1)})$ for $h = 1, \ldots, H_{\ell-1}$ is used as proposal.
This is equivalent to drawing an index $d \sim \mathcal{U}(\{1, \ldots, H_{\ell-1}\})$ and setting $\theta_{\ell - 1}^\star = \theta_{\ell - 1}^{(d, \ell - 1)}$, a process commonly known as resampling.
The resulting target-to-proposal density ratio simplifies as a result
\begin{align}
&\phantom{=} R(\theta_{\ell - 1}^\star, \psi_\ell, \theta_{\ell - 1}, \psi_\ell) \nonumber \\
&= \frac{p_\ell(\phi^\star, \psi_\ell, y_\ell)}{p_\ell(\phi^\star)} p_{\mathrm{pool}, \ell}(\phi^\star) \prod_{m=1}^{\ell - 1} \left(\frac{p_m(\phi^\star, \psi_m^\star, y_m)}{p_m(\phi^\star)} p_{\mathrm{pool}, m}(\phi^\star)\right) \cdot \frac{1}{q(\theta_{\ell - 1}^\star \, | \, \theta_{\ell - 1})} \nonumber \\
&= \frac{p_\ell(\phi^\star, \psi_\ell, y_\ell)}{p_\ell(\phi^\star)} p_{\mathrm{pool}, \ell}(\phi^\star) \frac{p_{\text{meld,}\ell - 1}(\phi^\star, \theta_{\ell - 1}^\star \, | \, y_1, \ldots, y_{\ell - 1})}{p_{\text{meld,}\ell - 1}(\phi^\star, \theta_{\ell - 1}^\star \, | \, y_1, \ldots, y_{\ell - 1})} \nonumber \\
&= \frac{p_\ell(\phi^\star, \psi_\ell, y_\ell)}{p_\ell(\phi^\star)} p_{\mathrm{pool}, \ell}(\phi^\star),
\end{align}
facilitating fast computation.

In the Markov melding framework, it is assumed that the set of studies to be synthesised and the statistical models for each study $m = 1, \ldots, M$ are prespecified.
In reality this is often not the case: practitioners may first fit a single submodel and then, based on the results, decide whether (or not) to include further evidence.
It could be argued that the above multi-stage MWG algorithm would computationally facilitate this sequential workflow.
However, for good reason, proponents of meta-analysis have suggested a systematic approach to study selection to avoid bias.
